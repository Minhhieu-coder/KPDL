{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# üåø PH√ÇN LO·∫†I V·∫æT B·ªÜNH TR√äN L√Å ƒê·∫¨U (Bean Leaf Lesions Classification)\n\n## B√†i T·∫≠p L·ªõn - M√¥n Khai Ph√° D·ªØ Li·ªáu\n\n---\n\n### üìã M·ª•c L·ª•c\n\n1. **Gi·ªõi thi·ªáu b√†i to√°n**\n2. **Nh·∫≠p th∆∞ vi·ªán & t·∫£i d·ªØ li·ªáu**\n3. **Kh√°m ph√° d·ªØ li·ªáu (EDA)**\n4. **Ti·ªÅn x·ª≠ l√Ω ·∫£nh**\n5. **X√¢y d·ª±ng m√¥ h√¨nh Deep Learning**\n6. **ƒê√°nh gi√° & ph√¢n t√≠ch k·∫øt qu·∫£**\n7. **So s√°nh m√¥ h√¨nh v√† k·∫øt lu·∫≠n**\n8. **ƒê·ªÅ xu·∫•t n√¢ng cao**\n\n---\n\n### üéØ Gi·ªõi thi·ªáu b√†i to√°n\n\n**Dataset:** Bean Leaf Lesions Classification t·ª´ Kaggle\n\n**M√¥ t·∫£:** Dataset g·ªìm ·∫£nh l√° ƒë·∫≠u thu·ªôc 3 tr·∫°ng th√°i:\n- üü¢ **Healthy** (l√° kh·ªèe)\n- üü° **Angular Leaf Spot** (v·∫øt b·ªánh g√≥c)\n- üî¥ **Bean Rust** (b·ªánh r·ªâ s·∫Øt)\n\n**Ngu·ªìn d·ªØ li·ªáu:** [Kaggle - Bean Leaf Lesions Classification](https://www.kaggle.com/datasets/marquis03/bean-leaf-lesions-classification)\n\n**M·ª•c ti√™u:** X√¢y d·ª±ng c√°c m√¥ h√¨nh Deep Learning ƒë·ªÉ ph√¢n lo·∫°i ch√≠nh x√°c c√°c tr·∫°ng th√°i b·ªánh tr√™n l√° ƒë·∫≠u, gi√∫p h·ªó tr·ª£ n√¥ng nghi·ªáp th√¥ng minh v√† ph√°t hi·ªán b·ªánh s·ªõm cho c√¢y tr·ªìng.\n\n---\n\n### üë• Th√¥ng tin nh√≥m & Ph√¢n c√¥ng nhi·ªám v·ª•\n\n| STT | H·ªç v√† T√™n | MSSV | Vai tr√≤ | M√¥ h√¨nh ph·ª• tr√°ch |\n|-----|-----------|------|---------|-------------------|\n| 1 | [Th√†nh vi√™n 1] | [MSSV] | Nh√≥m tr∆∞·ªüng | ResNet50 |\n| 2 | [Th√†nh vi√™n 2] | [MSSV] | Th√†nh vi√™n | MobileNetV2 |\n| 3 | [Th√†nh vi√™n 3] | [MSSV] | Th√†nh vi√™n | VGG19 |\n\n**Ph√¢n c√¥ng nhi·ªám v·ª• c·ª• th·ªÉ:**\n- **[Th√†nh vi√™n 1]:** Thu th·∫≠p d·ªØ li·ªáu, EDA, hu·∫•n luy·ªán ResNet50, vi·∫øt b√°o c√°o\n- **[Th√†nh vi√™n 2]:** Data Augmentation, hu·∫•n luy·ªán MobileNetV2, ƒë√°nh gi√° k·∫øt qu·∫£\n- **[Th√†nh vi√™n 3]:** Thi·∫øt k·∫ø m√¥ h√¨nh, hu·∫•n luy·ªán VGG19, t·ªëi ∆∞u hyperparameters\n\n> **L∆∞u √Ω:** M·ªói th√†nh vi√™n ƒë√£ √°p d·ª•ng √≠t nh·∫•t 1 m√¥ h√¨nh h·ªçc m√°y theo y√™u c·∫ßu ƒë·ªì √°n.\n\n---\n\n### üë®‚Äçüíª Th√¥ng tin k·ªπ thu·∫≠t\n\n- **Ng√†y t·∫°o:** 2024\n- **Framework:** TensorFlow/Keras\n- **Ng√¥n ng·ªØ:** Python 3.10+\n\n---"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1Ô∏è‚É£ Nh·∫≠p Th∆∞ Vi·ªán & Thi·∫øt L·∫≠p M√¥i Tr∆∞·ªùng\n\n### C√°c th∆∞ vi·ªán s·ª≠ d·ª•ng:\n- **numpy, pandas:** X·ª≠ l√Ω d·ªØ li·ªáu s·ªë v√† b·∫£ng\n- **matplotlib, seaborn:** Tr·ª±c quan h√≥a d·ªØ li·ªáu\n- **TensorFlow/Keras:** X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh Deep Learning\n- **scikit-learn:** ƒê√°nh gi√° v√† ph√¢n lo·∫°i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# NH·∫¨P C√ÅC TH∆Ø VI·ªÜN C·∫¶N THI·∫æT\n# ============================================\n\n# Th∆∞ vi·ªán x·ª≠ l√Ω d·ªØ li·ªáu\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nfrom pathlib import Path\nfrom collections import Counter\n\n# Th∆∞ vi·ªán tr·ª±c quan h√≥a\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# C·∫•u h√¨nh matplotlib cho ti·∫øng Vi·ªát\nplt.rcParams['font.size'] = 12\nplt.rcParams['axes.unicode_minus'] = False\n\n# Th∆∞ vi·ªán Deep Learning - TensorFlow/Keras\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50, MobileNetV2, VGG19\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Th∆∞ vi·ªán ƒë√°nh gi√° m√¥ h√¨nh\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.metrics import precision_score, recall_score, f1_score\n\n# Th∆∞ vi·ªán x·ª≠ l√Ω ·∫£nh\nfrom PIL import Image\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Ki·ªÉm tra phi√™n b·∫£n TensorFlow v√† GPU\nprint(\"=\" * 60)\nprint(\"TH√îNG TIN M√îI TR∆Ø·ªúNG\")\nprint(\"=\" * 60)\nprint(f\"TensorFlow version: {tf.__version__}\")\nprint(f\"Keras version: {keras.__version__}\")\nprint(f\"NumPy version: {np.__version__}\")\nprint(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")\n\n# Thi·∫øt l·∫≠p seed ƒë·ªÉ ƒë·∫£m b·∫£o k·∫øt qu·∫£ c√≥ th·ªÉ t√°i t·∫°o\nSEED = 42\nnp.random.seed(SEED)\ntf.random.set_seed(SEED)\nrandom.seed(SEED)\nprint(f\"\nRandom seed ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p: {SEED}\")\nprint(\"=\" * 60)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### üìÇ T·∫£i v√† ki·ªÉm tra c·∫•u tr√∫c d·ªØ li·ªáu\n\nB∆∞·ªõc n√†y ki·ªÉm tra c·∫•u tr√∫c th∆∞ m·ª•c ·∫£nh v√† c√°c nh√£n l·ªõp (classes) trong dataset."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# KI·ªÇM TRA C·∫§U TR√öC D·ªÆ LI·ªÜU\n# ============================================\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c d·ªØ li·ªáu\nDATA_DIR = './data'\n\n# Ki·ªÉm tra xem th∆∞ m·ª•c data c√≥ t·ªìn t·∫°i kh√¥ng\nif not os.path.exists(DATA_DIR):\n    print(\"Vui l√≤ng ch·∫°y: python download_dataset.py\")\nelse:\n    print(\"‚úÖ ƒê√£ t√¨m th·∫•y th∆∞ m·ª•c data\")\n    \n    # Li·ªát k√™ c√°c th∆∞ m·ª•c con\n    print(\"\nüìÅ C·∫•u tr√∫c th∆∞ m·ª•c d·ªØ li·ªáu:\")\n    for item in sorted(os.listdir(DATA_DIR)):\n        item_path = os.path.join(DATA_DIR, item)\n        if os.path.isdir(item_path):\n            sub_items = os.listdir(item_path)\n            print(f\"  üìÇ {item}/ ({len(sub_items)} m·ª•c)\")\n            # Hi·ªÉn th·ªã m·ªôt s·ªë m·ª•c con\n            for sub in sorted(sub_items)[:5]:\n                sub_path = os.path.join(item_path, sub)\n                if os.path.isdir(sub_path):\n                    files_in_sub = len(os.listdir(sub_path))\n                    print(f\"      üìÇ {sub}/ ({files_in_sub} ·∫£nh)\")\n        elif os.path.isfile(item_path) and item != 'README.md':\n            size_mb = os.path.getsize(item_path) / (1024 * 1024)\n            print(f\"  üìÑ {item} ({size_mb:.2f} MB)\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# THI·∫æT L·∫¨P ƒê∆Ø·ªúNG D·∫™N D·ªÆ LI·ªÜU\n# ============================================\n\n# ƒê∆∞·ªùng d·∫´n ƒë·∫øn c√°c t·∫≠p d·ªØ li·ªáu\n# C·∫•u tr√∫c th∆∞·ªùng g·∫∑p c·ªßa dataset n√†y:\n# data/\n#   ‚îú‚îÄ‚îÄ train/\n#   ‚îÇ   ‚îú‚îÄ‚îÄ angular_leaf_spot/\n#   ‚îÇ   ‚îú‚îÄ‚îÄ bean_rust/\n#   ‚îÇ   ‚îî‚îÄ‚îÄ healthy/\n#   ‚îî‚îÄ‚îÄ validation/ (ho·∫∑c test/)\n#       ‚îú‚îÄ‚îÄ angular_leaf_spot/\n#       ‚îú‚îÄ‚îÄ bean_rust/\n#       ‚îî‚îÄ‚îÄ healthy/\n\n# T·ª± ƒë·ªông ph√°t hi·ªán c·∫•u tr√∫c th∆∞ m·ª•c\ndef find_data_directories(base_path):\n    \"\"\"T√¨m c√°c th∆∞ m·ª•c train v√† validation trong dataset\"\"\"\n    train_dir = None\n    val_dir = None\n    \n    for item in os.listdir(base_path):\n        item_path = os.path.join(base_path, item)\n        if os.path.isdir(item_path):\n            item_lower = item.lower()\n            if 'train' in item_lower:\n                train_dir = item_path\n            elif 'val' in item_lower or 'test' in item_lower:\n                val_dir = item_path\n    \n    return train_dir, val_dir\n\nTRAIN_DIR, VAL_DIR = find_data_directories(DATA_DIR)\n\nprint(\"üìÅ ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu:\")\nprint(f\"   Train: {TRAIN_DIR}\")\nprint(f\"   Validation/Test: {VAL_DIR}\")\n\n# N·∫øu kh√¥ng t√¨m th·∫•y, s·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh\nif TRAIN_DIR is None:\n    TRAIN_DIR = os.path.join(DATA_DIR, 'train')\n    print(f\"\n‚ö†Ô∏è S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh cho train: {TRAIN_DIR}\")\n    \nif VAL_DIR is None:\n    VAL_DIR = os.path.join(DATA_DIR, 'validation')\n    print(f\"‚ö†Ô∏è S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n m·∫∑c ƒë·ªãnh cho validation: {VAL_DIR}\")\n\n# L·∫•y danh s√°ch c√°c l·ªõp (classes)\nif os.path.exists(TRAIN_DIR):\n    CLASSES = sorted([d for d in os.listdir(TRAIN_DIR) \n                      if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n    print(f\"\nüè∑Ô∏è C√°c l·ªõp ph√¢n lo·∫°i: {CLASSES}\")\n    print(f\"   S·ªë l∆∞·ª£ng l·ªõp: {len(CLASSES)}\")\nelse:\n    CLASSES = ['angular_leaf_spot', 'bean_rust', 'healthy']\n    print(f\"\n‚ö†Ô∏è S·ª≠ d·ª•ng danh s√°ch l·ªõp m·∫∑c ƒë·ªãnh: {CLASSES}\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## 2Ô∏è‚É£ Kh√°m Ph√° D·ªØ Li·ªáu (EDA - Exploratory Data Analysis)\n\nTrong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω:\n- ƒê·∫øm s·ªë l∆∞·ª£ng ·∫£nh theo t·ª´ng l·ªõp\n- Ph√¢n t√≠ch k√≠ch th∆∞·ªõc ·∫£nh\n- Hi·ªÉn th·ªã v√≠ d·ª• ·∫£nh tr·ª±c quan\n- V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë d·ªØ li·ªáu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# ƒê·∫æM S·ªê L∆Ø·ª¢NG ·∫¢NH THEO T·ª™NG L·ªöP\n# ============================================\n\ndef count_images_by_class(data_dir):\n    \"\"\"ƒê·∫øm s·ªë l∆∞·ª£ng ·∫£nh trong m·ªói l·ªõp c·ªßa th∆∞ m·ª•c d·ªØ li·ªáu\"\"\"\n    class_counts = {}\n    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']\n    \n    if not os.path.exists(data_dir):\n        return class_counts\n    \n    for class_name in os.listdir(data_dir):\n        class_path = os.path.join(data_dir, class_name)\n        if os.path.isdir(class_path):\n            count = 0\n            for file in os.listdir(class_path):\n                if any(file.lower().endswith(ext) for ext in image_extensions):\n                    count += 1\n            class_counts[class_name] = count\n    \n    return class_counts\n\n# ƒê·∫øm ·∫£nh trong t·∫≠p train\ntrain_counts = count_images_by_class(TRAIN_DIR)\nprint(\"üìä S·ªê L∆Ø·ª¢NG ·∫¢NH TRONG T·∫¨P TRAIN:\")\nprint(\"=\" * 40)\ntotal_train = 0\nfor class_name, count in sorted(train_counts.items()):\n    print(f\"   {class_name}: {count} ·∫£nh\")\n    total_train += count\nprint(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\nprint(f\"   T·ªïng c·ªông: {total_train} ·∫£nh\")\n\n# ƒê·∫øm ·∫£nh trong t·∫≠p validation/test\nval_counts = count_images_by_class(VAL_DIR)\nprint(\"\nüìä S·ªê L∆Ø·ª¢NG ·∫¢NH TRONG T·∫¨P VALIDATION/TEST:\")\nprint(\"=\" * 40)\ntotal_val = 0\nfor class_name, count in sorted(val_counts.items()):\n    print(f\"   {class_name}: {count} ·∫£nh\")\n    total_val += count\nprint(f\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\nprint(f\"   T·ªïng c·ªông: {total_val} ·∫£nh\")\n\nprint(f\"\nüìà T·ªîNG S·ªê ·∫¢NH TO√ÄN B·ªò DATASET: {total_train + total_val} ·∫£nh\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# BI·ªÇU ƒê·ªí THANH - PH√ÇN B·ªê ·∫¢NH THEO L·ªöP\n# ============================================\n\n# T·∫°o figure v·ªõi 2 subplot\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bi·ªÉu ƒë·ªì 1: T·∫≠p Train\nif train_counts:\n    classes = list(train_counts.keys())\n    counts = list(train_counts.values())\n    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']  # ƒê·ªè, Xanh l√°, Xanh d∆∞∆°ng\n    \n    bars1 = axes[0].bar(classes, counts, color=colors[:len(classes)], edgecolor='black', linewidth=1.2)\n    axes[0].set_title('üìä Ph√¢n B·ªë ·∫¢nh - T·∫≠p Train', fontsize=14, fontweight='bold')\n    axes[0].set_xlabel('Lo·∫°i B·ªánh', fontsize=12)\n    axes[0].set_ylabel('S·ªë L∆∞·ª£ng ·∫¢nh', fontsize=12)\n    axes[0].tick_params(axis='x', rotation=15)\n    \n    # Th√™m nh√£n s·ªë l∆∞·ª£ng tr√™n m·ªói c·ªôt\n    for bar, count in zip(bars1, counts):\n        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n                     str(count), ha='center', va='bottom', fontsize=11, fontweight='bold')\n\n# Bi·ªÉu ƒë·ªì 2: T·∫≠p Validation/Test\nif val_counts:\n    classes = list(val_counts.keys())\n    counts = list(val_counts.values())\n    \n    bars2 = axes[1].bar(classes, counts, color=colors[:len(classes)], edgecolor='black', linewidth=1.2)\n    axes[1].set_title('üìä Ph√¢n B·ªë ·∫¢nh - T·∫≠p Validation/Test', fontsize=14, fontweight='bold')\n    axes[1].set_xlabel('Lo·∫°i B·ªánh', fontsize=12)\n    axes[1].set_ylabel('S·ªë L∆∞·ª£ng ·∫¢nh', fontsize=12)\n    axes[1].tick_params(axis='x', rotation=15)\n    \n    # Th√™m nh√£n s·ªë l∆∞·ª£ng tr√™n m·ªói c·ªôt\n    for bar, count in zip(bars2, counts):\n        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n                     str(count), ha='center', va='bottom', fontsize=11, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('distribution_by_class.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\nüíæ Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u: distribution_by_class.png\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# BI·ªÇU ƒê·ªí TR√íN - T·ªà L·ªÜ PH·∫¶N TRƒÇM T·ª™NG L·ªöP\n# ============================================\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\nexplode = (0.05, 0.05, 0.05)  # T√°ch nh·∫π c√°c ph·∫ßn\n\n# Bi·ªÉu ƒë·ªì tr√≤n t·∫≠p Train\nif train_counts:\n    labels = list(train_counts.keys())\n    sizes = list(train_counts.values())\n    \n    wedges, texts, autotexts = axes[0].pie(\n        sizes, explode=explode[:len(sizes)], labels=labels, colors=colors[:len(sizes)],\n        autopct='%1.1f%%', shadow=True, startangle=90,\n        textprops={'fontsize': 11, 'fontweight': 'bold'}\n    )\n    axes[0].set_title('ü•ß T·ªâ L·ªá C√°c L·ªõp - T·∫≠p Train', fontsize=14, fontweight='bold')\n\n# Bi·ªÉu ƒë·ªì tr√≤n t·∫≠p Validation\nif val_counts:\n    labels = list(val_counts.keys())\n    sizes = list(val_counts.values())\n    \n    wedges, texts, autotexts = axes[1].pie(\n        sizes, explode=explode[:len(sizes)], labels=labels, colors=colors[:len(sizes)],\n        autopct='%1.1f%%', shadow=True, startangle=90,\n        textprops={'fontsize': 11, 'fontweight': 'bold'}\n    )\n    axes[1].set_title('ü•ß T·ªâ L·ªá C√°c L·ªõp - T·∫≠p Validation', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.savefig('pie_chart_distribution.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\nüíæ Bi·ªÉu ƒë·ªì tr√≤n ƒë√£ ƒë∆∞·ª£c l∆∞u: pie_chart_distribution.png\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# HI·ªÇN TH·ªä ·∫¢NH M·∫™U T·ª™ M·ªñI L·ªöP\n# ============================================\n\ndef display_sample_images(data_dir, num_samples=3):\n    \"\"\"Hi·ªÉn th·ªã ·∫£nh m·∫´u t·ª´ m·ªói l·ªõp trong dataset\"\"\"\n    if not os.path.exists(data_dir):\n        print(f\"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {data_dir}\")\n        return\n    \n    classes = sorted([d for d in os.listdir(data_dir) \n                      if os.path.isdir(os.path.join(data_dir, d))])\n    \n    if not classes:\n        print(\"‚ùå Kh√¥ng t√¨m th·∫•y l·ªõp n√†o trong th∆∞ m·ª•c\")\n        return\n    \n    fig, axes = plt.subplots(len(classes), num_samples, figsize=(4*num_samples, 4*len(classes)))\n    \n    # ƒê·∫£m b·∫£o axes l√† 2D array\n    if len(classes) == 1:\n        axes = [axes]\n    \n    class_labels = {\n        'angular_leaf_spot': 'üü° Angular Leaf Spot (V·∫øt B·ªánh G√≥c)',\n        'bean_rust': 'üî¥ Bean Rust (B·ªánh R·ªâ S·∫Øt)',\n        'healthy': 'üü¢ Healthy (L√° Kh·ªèe)'\n    }\n    \n    for i, class_name in enumerate(classes):\n        class_path = os.path.join(data_dir, class_name)\n        image_files = [f for f in os.listdir(class_path) \n                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n        \n        # Ch·ªçn ng·∫´u nhi√™n c√°c ·∫£nh m·∫´u\n        sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n        \n        for j, img_file in enumerate(sample_files):\n            img_path = os.path.join(class_path, img_file)\n            img = Image.open(img_path)\n            \n            axes[i][j].imshow(img)\n            axes[i][j].axis('off')\n            \n            # Ti√™u ƒë·ªÅ cho ·∫£nh ƒë·∫ßu ti√™n c·ªßa m·ªói l·ªõp\n            if j == 0:\n                label = class_labels.get(class_name, class_name)\n                axes[i][j].set_title(f'{label}', fontsize=12, fontweight='bold', loc='left')\n    \n    plt.suptitle('üñºÔ∏è ·∫¢nh M·∫´u T·ª´ M·ªói L·ªõp B·ªánh', fontsize=16, fontweight='bold', y=1.02)\n    plt.tight_layout()\n    plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(\"\nüíæ ·∫¢nh m·∫´u ƒë√£ ƒë∆∞·ª£c l∆∞u: sample_images.png\")\n\n# Hi·ªÉn th·ªã ·∫£nh m·∫´u t·ª´ t·∫≠p train\nprint(\"üì∏ ·∫¢NH M·∫™U T·ª™ T·∫¨P TRAIN:\")\nprint(\"=\" * 60)\ndisplay_sample_images(TRAIN_DIR, num_samples=4)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# PH√ÇN T√çCH K√çCH TH∆Ø·ªöC ·∫¢NH\n# ============================================\n\ndef analyze_image_sizes(data_dir, sample_size=100):\n    \"\"\"Ph√¢n t√≠ch k√≠ch th∆∞·ªõc ·∫£nh trong dataset\"\"\"\n    widths = []\n    heights = []\n    aspect_ratios = []\n    \n    if not os.path.exists(data_dir):\n        return widths, heights, aspect_ratios\n    \n    all_images = []\n    for class_name in os.listdir(data_dir):\n        class_path = os.path.join(data_dir, class_name)\n        if os.path.isdir(class_path):\n            for img_file in os.listdir(class_path):\n                if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n                    all_images.append(os.path.join(class_path, img_file))\n    \n    # L·∫•y m·∫´u ng·∫´u nhi√™n ƒë·ªÉ ph√¢n t√≠ch\n    sample_images = random.sample(all_images, min(sample_size, len(all_images)))\n    \n    for img_path in sample_images:\n        try:\n            with Image.open(img_path) as img:\n                w, h = img.size\n                widths.append(w)\n                heights.append(h)\n                aspect_ratios.append(w / h)\n        except Exception as e:\n            continue\n    \n    return widths, heights, aspect_ratios\n\n# Ph√¢n t√≠ch k√≠ch th∆∞·ªõc ·∫£nh\nwidths, heights, aspect_ratios = analyze_image_sizes(TRAIN_DIR, sample_size=200)\n\nif widths:\n    print(\"üìê PH√ÇN T√çCH K√çCH TH∆Ø·ªöC ·∫¢NH:\")\n    print(\"=\" * 50)\n    print(f\"   S·ªë ·∫£nh ph√¢n t√≠ch: {len(widths)}\")\n    print(f\"\n   üìè Chi·ªÅu r·ªông (Width):\")\n    print(f\"      Min: {min(widths)} px\")\n    print(f\"      Max: {max(widths)} px\")\n    print(f\"      Trung b√¨nh: {np.mean(widths):.1f} px\")\n    print(f\"\n   üìè Chi·ªÅu cao (Height):\")\n    print(f\"      Min: {min(heights)} px\")\n    print(f\"      Max: {max(heights)} px\")\n    print(f\"      Trung b√¨nh: {np.mean(heights):.1f} px\")\n    print(f\"\n   üìê T·ªâ l·ªá khung h√¨nh (Aspect Ratio):\")\n    print(f\"      Min: {min(aspect_ratios):.3f}\")\n    print(f\"      Max: {max(aspect_ratios):.3f}\")\n    print(f\"      Trung b√¨nh: {np.mean(aspect_ratios):.3f}\")\n    \n    # V·∫Ω histogram k√≠ch th∆∞·ªõc\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    \n    axes[0].hist(widths, bins=20, color='#FF6B6B', edgecolor='black', alpha=0.7)\n    axes[0].set_title('Ph√¢n B·ªë Chi·ªÅu R·ªông', fontsize=12, fontweight='bold')\n    axes[0].set_xlabel('Width (px)')\n    axes[0].set_ylabel('S·ªë l∆∞·ª£ng ·∫£nh')\n    axes[0].axvline(np.mean(widths), color='red', linestyle='--', label=f'Mean: {np.mean(widths):.0f}')\n    axes[0].legend()\n    \n    axes[1].hist(heights, bins=20, color='#4ECDC4', edgecolor='black', alpha=0.7)\n    axes[1].set_title('Ph√¢n B·ªë Chi·ªÅu Cao', fontsize=12, fontweight='bold')\n    axes[1].set_xlabel('Height (px)')\n    axes[1].set_ylabel('S·ªë l∆∞·ª£ng ·∫£nh')\n    axes[1].axvline(np.mean(heights), color='red', linestyle='--', label=f'Mean: {np.mean(heights):.0f}')\n    axes[1].legend()\n    \n    axes[2].hist(aspect_ratios, bins=20, color='#45B7D1', edgecolor='black', alpha=0.7)\n    axes[2].set_title('Ph√¢n B·ªë T·ªâ L·ªá Khung H√¨nh', fontsize=12, fontweight='bold')\n    axes[2].set_xlabel('Aspect Ratio (W/H)')\n    axes[2].set_ylabel('S·ªë l∆∞·ª£ng ·∫£nh')\n    axes[2].axvline(np.mean(aspect_ratios), color='red', linestyle='--', label=f'Mean: {np.mean(aspect_ratios):.2f}')\n    axes[2].legend()\n    \n    plt.tight_layout()\n    plt.savefig('image_size_distribution.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(\"\nüíæ Bi·ªÉu ƒë·ªì ph√¢n b·ªë k√≠ch th∆∞·ªõc ƒë√£ ƒë∆∞·ª£c l∆∞u: image_size_distribution.png\")\nelse:\n    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ·∫£nh ƒë·ªÉ ph√¢n t√≠ch\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### üìù T·ªïng K·∫øt Kh√°m Ph√° D·ªØ Li·ªáu (EDA)\n\n**Nh·ªØng ƒëi·ªÉm ch√≠nh t·ª´ EDA:**\n\n1. **S·ªë l∆∞·ª£ng d·ªØ li·ªáu:** Dataset g·ªìm kho·∫£ng ~1034 ·∫£nh train v√† ~133 ·∫£nh validation/test\n2. **Ph√¢n b·ªë l·ªõp:** D·ªØ li·ªáu t∆∞∆°ng ƒë·ªëi c√¢n b·∫±ng gi·ªØa 3 l·ªõp\n3. **K√≠ch th∆∞·ªõc ·∫£nh:** ·∫¢nh c√≥ k√≠ch th∆∞·ªõc ƒëa d·∫°ng, c·∫ßn resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n (224x224)\n4. **Ch·∫•t l∆∞·ª£ng ·∫£nh:** ·∫¢nh r√µ r√†ng, d·ªÖ nh·∫≠n di·ªán ƒë·∫∑c ƒëi·ªÉm b·ªánh\n\n**Nh·∫≠n x√©t:**\n- Dataset c√≥ quy m√¥ v·ª´a ph·∫£i, ph√π h·ª£p cho vi·ªác th·ª≠ nghi·ªám c√°c m√¥ h√¨nh Transfer Learning\n- C·∫ßn s·ª≠ d·ª•ng Data Augmentation ƒë·ªÉ tƒÉng s·ªë l∆∞·ª£ng ·∫£nh v√† tr√°nh overfitting\n- C√°c l·ªõp c√≥ s·ª± kh√°c bi·ªát r√µ r√†ng v·ªÅ m√†u s·∫Øc v√† h√¨nh d·∫°ng v·∫øt b·ªánh"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## 3Ô∏è‚É£ Ti·ªÅn X·ª≠ L√Ω ·∫¢nh (Image Preprocessing)\n\nTrong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω:\n- Resize ·∫£nh v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n (224√ó224)\n- Chu·∫©n h√≥a gi√° tr·ªã pixel\n- Chia t·∫≠p Train/Validation\n- √Åp d·ª•ng Data Augmentation ƒë·ªÉ tƒÉng c∆∞·ªùng d·ªØ li·ªáu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# THI·∫æT L·∫¨P THAM S·ªê TI·ªÄN X·ª¨ L√ù\n# ============================================\n\n# K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o cho m√¥ h√¨nh\nIMG_HEIGHT = 224\nIMG_WIDTH = 224\nIMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)\n\n# Batch size - s·ªë ·∫£nh x·ª≠ l√Ω c√πng l√∫c\nBATCH_SIZE = 32\n\n# S·ªë l·ªõp ph√¢n lo·∫°i\nNUM_CLASSES = len(CLASSES) if CLASSES else 3\n\nprint(\"‚öôÔ∏è THAM S·ªê TI·ªÄN X·ª¨ L√ù:\")\nprint(\"=\" * 40)\nprint(f\"   K√≠ch th∆∞·ªõc ·∫£nh: {IMG_WIDTH} x {IMG_HEIGHT}\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   S·ªë l·ªõp ph√¢n lo·∫°i: {NUM_CLASSES}\")\nprint(f\"   C√°c l·ªõp: {CLASSES}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# T·∫†O DATA GENERATORS V·ªöI AUGMENTATION\n# ============================================\n\n# Data Augmentation cho t·∫≠p Train\n# C√°c k·ªπ thu·∫≠t augmentation gi√∫p:\n# - TƒÉng s·ªë l∆∞·ª£ng d·ªØ li·ªáu ·∫£o\n# - Gi·∫£m overfitting\n# - M√¥ h√¨nh h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng b·∫•t bi·∫øn\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,              # Chu·∫©n h√≥a pixel v·ªÅ [0, 1]\n    rotation_range=40,           # Xoay ng·∫´u nhi√™n 0-40 ƒë·ªô\n    width_shift_range=0.2,       # D·ªãch ngang 20%\n    height_shift_range=0.2,      # D·ªãch d·ªçc 20%\n    shear_range=0.2,             # C·∫Øt nghi√™ng\n    zoom_range=0.2,              # Ph√≥ng to/thu nh·ªè 20%\n    horizontal_flip=True,        # L·∫≠t ngang\n    vertical_flip=True,          # L·∫≠t d·ªçc\n    brightness_range=[0.8, 1.2], # Thay ƒë·ªïi ƒë·ªô s√°ng\n    fill_mode='nearest'          # ƒêi·ªÅn pixel khi bi·∫øn ƒë·ªïi\n)\n\n# Data Generator cho t·∫≠p Validation (ch·ªâ chu·∫©n h√≥a, kh√¥ng augmentation)\nval_datagen = ImageDataGenerator(\n    rescale=1./255\n)\n\nprint(\"‚úÖ ƒê√£ t·∫°o Data Generators v·ªõi c√°c k·ªπ thu·∫≠t Augmentation:\")\nprint(\"   - Xoay ·∫£nh (rotation)\")\nprint(\"   - D·ªãch chuy·ªÉn (shift)\")\nprint(\"   - C·∫Øt nghi√™ng (shear)\")\nprint(\"   - Ph√≥ng to/thu nh·ªè (zoom)\")\nprint(\"   - L·∫≠t ngang/d·ªçc (flip)\")\nprint(\"   - Thay ƒë·ªïi ƒë·ªô s√°ng (brightness)\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# T·∫¢I D·ªÆ LI·ªÜU T·ª™ TH∆Ø M·ª§C\n# ============================================\n\n# T·∫°o generator cho t·∫≠p Train\nprint(\"üìÇ ƒêang t·∫£i d·ªØ li·ªáu train...\")\ntrain_generator = train_datagen.flow_from_directory(\n    TRAIN_DIR,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=SEED\n)\n\n# T·∫°o generator cho t·∫≠p Validation\nprint(\"\\nüìÇ ƒêang t·∫£i d·ªØ li·ªáu validation...\")\nval_generator = val_datagen.flow_from_directory(\n    VAL_DIR,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False\n)\n\n# L∆∞u mapping class\nclass_indices = train_generator.class_indices\nclass_names = list(class_indices.keys())\n\nprint(\"\\n\" + \"=\" * 50)\nprint(\"üìä TH√îNG TIN D·ªÆ LI·ªÜU:\")\nprint(\"=\" * 50)\nprint(f\"   T·∫≠p Train: {train_generator.samples} ·∫£nh\")\nprint(f\"   T·∫≠p Validation: {val_generator.samples} ·∫£nh\")\nprint(f\"   S·ªë b∆∞·ªõc/epoch (train): {len(train_generator)}\")\nprint(f\"   S·ªë b∆∞·ªõc/epoch (val): {len(val_generator)}\")\nprint(f\"\\n   Class mapping: {class_indices}\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# HI·ªÇN TH·ªä ·∫¢NH SAU KHI AUGMENTATION\n# ============================================\n\ndef show_augmented_images(generator, num_images=8):\n    \"\"\"Hi·ªÉn th·ªã ·∫£nh sau khi √°p d·ª•ng augmentation\"\"\"\n    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n    axes = axes.flatten()\n    \n    # L·∫•y m·ªôt batch ·∫£nh\n    images, labels = next(generator)\n    \n    for i in range(min(num_images, len(images))):\n        axes[i].imshow(images[i])\n        axes[i].axis('off')\n        \n        # T√¨m t√™n l·ªõp t·ª´ one-hot encoding\n        class_idx = np.argmax(labels[i])\n        class_name = class_names[class_idx]\n        axes[i].set_title(f'{class_name}', fontsize=11, fontweight='bold')\n    \n    plt.suptitle('üîÑ ·∫¢nh Sau Khi Data Augmentation', fontsize=16, fontweight='bold')\n    plt.tight_layout()\n    plt.savefig('augmented_images.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(\"\\nüíæ ·∫¢nh augmentation ƒë√£ ƒë∆∞·ª£c l∆∞u: augmented_images.png\")\n\n# Hi·ªÉn th·ªã ·∫£nh sau augmentation\nprint(\"üîÑ ·∫¢NH SAU KHI √ÅP D·ª§NG DATA AUGMENTATION:\")\nprint(\"=\" * 60)\nshow_augmented_images(train_generator)\n\n# Reset generator\ntrain_generator.reset()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## 4Ô∏è‚É£ X√¢y D·ª±ng M√¥ H√¨nh Deep Learning\n\nTrong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω x√¢y d·ª±ng v√† hu·∫•n luy·ªán **3 m√¥ h√¨nh Transfer Learning** kh√°c nhau:\n\n1. **ResNet50** - M√¥ h√¨nh s√¢u v·ªõi k·∫øt n·ªëi t·∫Øt (skip connections)\n2. **MobileNetV2** - M√¥ h√¨nh nh·∫π, t·ªëi ∆∞u cho thi·∫øt b·ªã di ƒë·ªông\n3. **VGG19** - M√¥ h√¨nh c·ªï ƒëi·ªÉn v·ªõi ki·∫øn tr√∫c ƒë∆°n gi·∫£n\n\n### Transfer Learning l√† g√¨?\n\nTransfer Learning (H·ªçc chuy·ªÉn giao) l√† k·ªπ thu·∫≠t s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán tr√™n t·∫≠p d·ªØ li·ªáu l·ªõn (nh∆∞ ImageNet) v√† tinh ch·ªânh (fine-tune) cho b√†i to√°n c·ª• th·ªÉ c·ªßa m√¨nh.\n\n**∆Øu ƒëi·ªÉm:**\n- Ti·∫øt ki·ªám th·ªùi gian hu·∫•n luy·ªán\n- Y√™u c·∫ßu √≠t d·ªØ li·ªáu h∆°n\n- ƒê·∫°t ƒë·ªô ch√≠nh x√°c cao h∆°n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# THI·∫æT L·∫¨P THAM S·ªê HU·∫§N LUY·ªÜN\n# ============================================\n\n# S·ªë epoch hu·∫•n luy·ªán\nEPOCHS = 20\n\n# Learning rate\nLEARNING_RATE = 0.0001\n\n# Early stopping patience\nPATIENCE = 5\n\nprint(\"‚öôÔ∏è THAM S·ªê HU·∫§N LUY·ªÜN:\")\nprint(\"=\" * 40)\nprint(f\"   S·ªë epoch: {EPOCHS}\")\nprint(f\"   Learning rate: {LEARNING_RATE}\")\nprint(f\"   Early stopping patience: {PATIENCE}\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   Input shape: ({IMG_HEIGHT}, {IMG_WIDTH}, 3)\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# THI·∫æT L·∫¨P CALLBACKS\n# ============================================\n\ndef get_callbacks(model_name):\n    \"\"\"T·∫°o callbacks cho qu√° tr√¨nh hu·∫•n luy·ªán\"\"\"\n    \n    # Early Stopping - d·ª´ng s·ªõm khi kh√¥ng c·∫£i thi·ªán\n    early_stop = EarlyStopping(\n        monitor='val_loss',\n        patience=PATIENCE,\n        restore_best_weights=True,\n        verbose=1\n    )\n    \n    # Reduce Learning Rate - gi·∫£m learning rate khi kh√¥ng c·∫£i thi·ªán\n    reduce_lr = ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.2,\n        patience=3,\n        min_lr=1e-7,\n        verbose=1\n    )\n    \n    # Model Checkpoint - l∆∞u model t·ªët nh·∫•t\n    checkpoint = ModelCheckpoint(\n        f'best_{model_name}.keras',\n        monitor='val_accuracy',\n        save_best_only=True,\n        mode='max',\n        verbose=1\n    )\n    \n    return [early_stop, reduce_lr, checkpoint]\n\nprint(\"‚úÖ ƒê√£ thi·∫øt l·∫≠p callbacks:\")\nprint(\"   - Early Stopping: D·ª´ng khi val_loss kh√¥ng c·∫£i thi·ªán sau 5 epoch\")\nprint(\"   - Reduce LR: Gi·∫£m learning rate khi val_loss kh√¥ng c·∫£i thi·ªán\")\nprint(\"   - Model Checkpoint: L∆∞u model c√≥ val_accuracy cao nh·∫•t\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# H√ÄM X√ÇY D·ª∞NG M√î H√åNH TRANSFER LEARNING\n# ============================================\n\ndef build_transfer_model(base_model_class, model_name, input_shape=(224, 224, 3), num_classes=3):\n    \"\"\"\n    X√¢y d·ª±ng m√¥ h√¨nh Transfer Learning\n    \n    Parameters:\n    - base_model_class: Class c·ªßa m√¥ h√¨nh c∆° s·ªü (ResNet50, MobileNetV2, VGG19)\n    - model_name: T√™n m√¥ h√¨nh (ƒë·ªÉ in th√¥ng tin)\n    - input_shape: K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o\n    - num_classes: S·ªë l·ªõp ph√¢n lo·∫°i\n    \n    Returns:\n    - model: M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng\n    \"\"\"\n    \n    print(f\"\\nüî® ƒêang x√¢y d·ª±ng m√¥ h√¨nh {model_name}...\")\n    print(\"=\" * 50)\n    \n    # T·∫£i m√¥ h√¨nh pretrained (kh√¥ng bao g·ªìm l·ªõp fully connected cu·ªëi)\n    base_model = base_model_class(\n        weights='imagenet',\n        include_top=False,\n        input_shape=input_shape\n    )\n    \n    # ƒê√≥ng bƒÉng c√°c layer c·ªßa base model\n    base_model.trainable = False\n    \n    # X√¢y d·ª±ng m√¥ h√¨nh ho√†n ch·ªânh\n    model = models.Sequential([\n        # Base model (pretrained)\n        base_model,\n        \n        # Global Average Pooling\n        layers.GlobalAveragePooling2D(),\n        \n        # Dense layers (fully connected)\n        layers.Dense(512, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.5),\n        \n        layers.Dense(256, activation='relu'),\n        layers.BatchNormalization(),\n        layers.Dropout(0.3),\n        \n        # Output layer\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    # Compile model\n    model.compile(\n        optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n        loss='categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    print(f\"   ‚úÖ M√¥ h√¨nh {model_name} ƒë√£ ƒë∆∞·ª£c x√¢y d·ª±ng!\")\n    print(f\"   üìä T·ªïng s·ªë parameters: {model.count_params():,}\")\n    print(f\"   üìä Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in model.trainable_weights]):,}\")\n    \n    return model"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.1 M√¥ h√¨nh ResNet50\n\n**ResNet50** (Residual Network) l√† m√¥ h√¨nh v·ªõi 50 layers, s·ª≠ d·ª•ng k·∫øt n·ªëi t·∫Øt (skip connections) ƒë·ªÉ gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ vanishing gradient trong m·∫°ng s√¢u.\n\n**ƒê·∫∑c ƒëi·ªÉm:**\n- 50 layers v·ªõi 25.6M parameters\n- Skip connections gi√∫p training ·ªïn ƒë·ªãnh\n- Ph√π h·ª£p cho nhi·ªÅu b√†i to√°n ph√¢n lo·∫°i ·∫£nh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# X√ÇY D·ª∞NG V√Ä HU·∫§N LUY·ªÜN M√î H√åNH RESNET50\n# ============================================\n\n# X√¢y d·ª±ng m√¥ h√¨nh ResNet50\nmodel_resnet = build_transfer_model(\n    ResNet50, \n    'ResNet50', \n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n    num_classes=NUM_CLASSES\n)\n\n# Hi·ªÉn th·ªã ki·∫øn tr√∫c m√¥ h√¨nh\nprint(\"\\nüìã KI·∫æN TR√öC M√î H√åNH RESNET50:\")\nmodel_resnet.summary()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# HU·∫§N LUY·ªÜN M√î H√åNH RESNET50\n# ============================================\n\nprint(\"\\nüöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN RESNET50\")\nprint(\"=\" * 60)\n\n# Reset generators\ntrain_generator.reset()\nval_generator.reset()\n\n# Hu·∫•n luy·ªán m√¥ h√¨nh\nhistory_resnet = model_resnet.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=val_generator,\n    callbacks=get_callbacks('resnet50'),\n    verbose=1\n)\n\nprint(\"\\n‚úÖ Ho√†n th√†nh hu·∫•n luy·ªán ResNet50!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.2 M√¥ h√¨nh MobileNetV2\n\n**MobileNetV2** l√† m√¥ h√¨nh nh·∫π, ƒë∆∞·ª£c t·ªëi ∆∞u cho c√°c thi·∫øt b·ªã c√≥ t√†i nguy√™n h·∫°n ch·∫ø (mobile, embedded devices).\n\n**ƒê·∫∑c ƒëi·ªÉm:**\n- S·ª≠ d·ª•ng Depthwise Separable Convolutions\n- Inverted Residuals v·ªõi Linear Bottlenecks\n- Ch·ªâ 3.4M parameters (nh·∫π h∆°n nhi·ªÅu so v·ªõi ResNet50)\n- Ph√π h·ª£p cho ·ª©ng d·ª•ng th·ªùi gian th·ª±c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# X√ÇY D·ª∞NG V√Ä HU·∫§N LUY·ªÜN M√î H√åNH MOBILENETV2\n# ============================================\n\n# X√¢y d·ª±ng m√¥ h√¨nh MobileNetV2\nmodel_mobilenet = build_transfer_model(\n    MobileNetV2, \n    'MobileNetV2', \n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n    num_classes=NUM_CLASSES\n)\n\n# Hi·ªÉn th·ªã ki·∫øn tr√∫c m√¥ h√¨nh\nprint(\"\\nüìã KI·∫æN TR√öC M√î H√åNH MOBILENETV2:\")\nmodel_mobilenet.summary()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# HU·∫§N LUY·ªÜN M√î H√åNH MOBILENETV2\n# ============================================\n\nprint(\"\\nüöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN MOBILENETV2\")\nprint(\"=\" * 60)\n\n# Reset generators\ntrain_generator.reset()\nval_generator.reset()\n\n# Hu·∫•n luy·ªán m√¥ h√¨nh\nhistory_mobilenet = model_mobilenet.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=val_generator,\n    callbacks=get_callbacks('mobilenetv2'),\n    verbose=1\n)\n\nprint(\"\\n‚úÖ Ho√†n th√†nh hu·∫•n luy·ªán MobileNetV2!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 4.3 M√¥ h√¨nh VGG19\n\n**VGG19** l√† m√¥ h√¨nh c·ªï ƒëi·ªÉn t·ª´ Visual Geometry Group (Oxford), v·ªõi ki·∫øn tr√∫c ƒë∆°n gi·∫£n nh∆∞ng hi·ªáu qu·∫£.\n\n**ƒê·∫∑c ƒëi·ªÉm:**\n- 19 layers (16 convolutional + 3 fully connected)\n- S·ª≠ d·ª•ng to√†n b·ªô 3x3 convolutions\n- 143.7M parameters (n·∫∑ng nh·∫•t trong 3 m√¥ h√¨nh)\n- ƒê·∫°t k·∫øt qu·∫£ t·ªët tr√™n nhi·ªÅu b√†i to√°n ph√¢n lo·∫°i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# X√ÇY D·ª∞NG V√Ä HU·∫§N LUY·ªÜN M√î H√åNH VGG19\n# ============================================\n\n# X√¢y d·ª±ng m√¥ h√¨nh VGG19\nmodel_vgg = build_transfer_model(\n    VGG19, \n    'VGG19', \n    input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n    num_classes=NUM_CLASSES\n)\n\n# Hi·ªÉn th·ªã ki·∫øn tr√∫c m√¥ h√¨nh\nprint(\"\\nüìã KI·∫æN TR√öC M√î H√åNH VGG19:\")\nmodel_vgg.summary()"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# HU·∫§N LUY·ªÜN M√î H√åNH VGG19\n# ============================================\n\nprint(\"\\nüöÄ B·∫ÆT ƒê·∫¶U HU·∫§N LUY·ªÜN VGG19\")\nprint(\"=\" * 60)\n\n# Reset generators\ntrain_generator.reset()\nval_generator.reset()\n\n# Hu·∫•n luy·ªán m√¥ h√¨nh\nhistory_vgg = model_vgg.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=val_generator,\n    callbacks=get_callbacks('vgg19'),\n    verbose=1\n)\n\nprint(\"\\n‚úÖ Ho√†n th√†nh hu·∫•n luy·ªán VGG19!\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## 5Ô∏è‚É£ ƒê√°nh Gi√° & Ph√¢n T√≠ch K·∫øt Qu·∫£\n\nTrong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω:\n- V·∫Ω Learning Curves (Loss v√† Accuracy theo epoch)\n- T√≠nh c√°c metrics: Accuracy, Precision, Recall, F1-score\n- Hi·ªÉn th·ªã Confusion Matrix\n- So s√°nh hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# H√ÄM V·∫º LEARNING CURVES\n# ============================================\n\ndef plot_learning_curves(history, model_name):\n    \"\"\"\n    V·∫Ω bi·ªÉu ƒë·ªì Learning Curves cho m·ªôt m√¥ h√¨nh\n    \n    Parameters:\n    - history: L·ªãch s·ª≠ hu·∫•n luy·ªán t·ª´ model.fit()\n    - model_name: T√™n m√¥ h√¨nh (ƒë·ªÉ hi·ªÉn th·ªã ti√™u ƒë·ªÅ)\n    \"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # L·∫•y d·ªØ li·ªáu t·ª´ history\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs_range = range(1, len(acc) + 1)\n    \n    # Bi·ªÉu ƒë·ªì Accuracy\n    axes[0].plot(epochs_range, acc, 'b-', label='Training Accuracy', linewidth=2)\n    axes[0].plot(epochs_range, val_acc, 'r-', label='Validation Accuracy', linewidth=2)\n    axes[0].set_title(f'{model_name} - Accuracy', fontsize=14, fontweight='bold')\n    axes[0].set_xlabel('Epoch', fontsize=12)\n    axes[0].set_ylabel('Accuracy', fontsize=12)\n    axes[0].legend(loc='lower right', fontsize=10)\n    axes[0].grid(True, alpha=0.3)\n    axes[0].set_ylim([0, 1])\n    \n    # Bi·ªÉu ƒë·ªì Loss\n    axes[1].plot(epochs_range, loss, 'b-', label='Training Loss', linewidth=2)\n    axes[1].plot(epochs_range, val_loss, 'r-', label='Validation Loss', linewidth=2)\n    axes[1].set_title(f'{model_name} - Loss', fontsize=14, fontweight='bold')\n    axes[1].set_xlabel('Epoch', fontsize=12)\n    axes[1].set_ylabel('Loss', fontsize=12)\n    axes[1].legend(loc='upper right', fontsize=10)\n    axes[1].grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.savefig(f'learning_curves_{model_name.lower().replace(\" \", \"_\")}.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # In k·∫øt qu·∫£ cu·ªëi c√πng\n    print(f\"\\nüìä K·∫æT QU·∫¢ HU·∫§N LUY·ªÜN {model_name.upper()}:\")\n    print(\"=\" * 50)\n    print(f\"   Training Accuracy (cu·ªëi): {acc[-1]:.4f}\")\n    print(f\"   Validation Accuracy (cu·ªëi): {val_acc[-1]:.4f}\")\n    print(f\"   Training Loss (cu·ªëi): {loss[-1]:.4f}\")\n    print(f\"   Validation Loss (cu·ªëi): {val_loss[-1]:.4f}\")\n    print(f\"   Best Validation Accuracy: {max(val_acc):.4f} (Epoch {val_acc.index(max(val_acc)) + 1})\")\n\nprint(\"‚úÖ H√†m v·∫Ω Learning Curves ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# V·∫º LEARNING CURVES CHO T·∫§T C·∫¢ M√î H√åNH\n# ============================================\n\nprint(\"üìà LEARNING CURVES - RESNET50\")\nprint(\"=\" * 60)\nplot_learning_curves(history_resnet, 'ResNet50')\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"üìà LEARNING CURVES - MOBILENETV2\")\nprint(\"=\" * 60)\nplot_learning_curves(history_mobilenet, 'MobileNetV2')\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"üìà LEARNING CURVES - VGG19\")\nprint(\"=\" * 60)\nplot_learning_curves(history_vgg, 'VGG19')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# H√ÄM ƒê√ÅNH GI√Å M√î H√åNH\n# ============================================\n\ndef evaluate_model(model, generator, model_name, class_names):\n    \"\"\"\n    ƒê√°nh gi√° m√¥ h√¨nh v√† hi·ªÉn th·ªã c√°c metrics\n    \n    Parameters:\n    - model: M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n    - generator: Data generator cho t·∫≠p test/validation\n    - model_name: T√™n m√¥ h√¨nh\n    - class_names: Danh s√°ch t√™n c√°c l·ªõp\n    \n    Returns:\n    - metrics_dict: Dictionary ch·ª©a c√°c metrics\n    \"\"\"\n    print(f\"\\nüìä ƒê√ÅNH GI√Å M√î H√åNH: {model_name}\")\n    print(\"=\" * 60)\n    \n    # Reset generator v√† l·∫•y t·∫•t c·∫£ d·ªØ li·ªáu\n    generator.reset()\n    \n    # D·ª± ƒëo√°n\n    predictions = model.predict(generator, verbose=1)\n    y_pred = np.argmax(predictions, axis=1)\n    y_true = generator.classes\n    \n    # T√≠nh c√°c metrics\n    accuracy = accuracy_score(y_true, y_pred)\n    precision = precision_score(y_true, y_pred, average='weighted')\n    recall = recall_score(y_true, y_pred, average='weighted')\n    f1 = f1_score(y_true, y_pred, average='weighted')\n    \n    # In k·∫øt qu·∫£\n    print(f\"\\nüìà METRICS T·ªîNG QUAN:\")\n    print(f\"   Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(f\"   Precision: {precision:.4f}\")\n    print(f\"   Recall:    {recall:.4f}\")\n    print(f\"   F1-Score:  {f1:.4f}\")\n    \n    # Classification Report chi ti·∫øt\n    print(f\"\\nüìã CLASSIFICATION REPORT:\")\n    print(\"-\" * 60)\n    report = classification_report(y_true, y_pred, target_names=class_names)\n    print(report)\n    \n    # Tr·∫£ v·ªÅ metrics\n    metrics_dict = {\n        'model_name': model_name,\n        'accuracy': accuracy,\n        'precision': precision,\n        'recall': recall,\n        'f1_score': f1,\n        'y_true': y_true,\n        'y_pred': y_pred\n    }\n    \n    return metrics_dict\n\nprint(\"‚úÖ H√†m ƒë√°nh gi√° m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# H√ÄM V·∫º CONFUSION MATRIX\n# ============================================\n\ndef plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n    \"\"\"\n    V·∫Ω Confusion Matrix v·ªõi heatmap\n    \n    Parameters:\n    - y_true: Nh√£n th·ª±c t·∫ø\n    - y_pred: Nh√£n d·ª± ƒëo√°n\n    - class_names: Danh s√°ch t√™n c√°c l·ªõp\n    - model_name: T√™n m√¥ h√¨nh\n    \"\"\"\n    # T√≠nh confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    \n    # V·∫Ω heatmap\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(\n        cm, \n        annot=True, \n        fmt='d', \n        cmap='Blues',\n        xticklabels=class_names,\n        yticklabels=class_names,\n        annot_kws={'size': 14, 'fontweight': 'bold'}\n    )\n    \n    plt.title(f'Confusion Matrix - {model_name}', fontsize=16, fontweight='bold')\n    plt.xlabel('D·ª± ƒêo√°n (Predicted)', fontsize=12)\n    plt.ylabel('Th·ª±c T·∫ø (Actual)', fontsize=12)\n    \n    plt.tight_layout()\n    plt.savefig(f'confusion_matrix_{model_name.lower().replace(\" \", \"_\")}.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    # Ph√¢n t√≠ch confusion matrix\n    print(f\"\\nüìä PH√ÇN T√çCH CONFUSION MATRIX - {model_name}:\")\n    print(\"=\" * 50)\n    total = np.sum(cm)\n    for i, class_name in enumerate(class_names):\n        tp = cm[i, i]\n        fn = np.sum(cm[i, :]) - tp\n        fp = np.sum(cm[:, i]) - tp\n        tn = total - tp - fn - fp\n        \n        class_accuracy = tp / np.sum(cm[i, :]) if np.sum(cm[i, :]) > 0 else 0\n        print(f\"   {class_name}:\")\n        print(f\"      - D·ª± ƒëo√°n ƒë√∫ng: {tp}/{np.sum(cm[i, :])} ({class_accuracy*100:.1f}%)\")\n        print(f\"      - D·ª± ƒëo√°n sai: {fn}/{np.sum(cm[i, :])} ({(1-class_accuracy)*100:.1f}%)\")\n\nprint(\"‚úÖ H√†m v·∫Ω Confusion Matrix ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# ƒê√ÅNH GI√Å T·∫§T C·∫¢ C√ÅC M√î H√åNH\n# ============================================\n\n# ƒê√°nh gi√° ResNet50\nprint(\"\\n\" + \"=\" * 70)\nprint(\"üîµ ƒê√ÅNH GI√Å M√î H√åNH RESNET50\")\nprint(\"=\" * 70)\nmetrics_resnet = evaluate_model(model_resnet, val_generator, 'ResNet50', class_names)\nplot_confusion_matrix(metrics_resnet['y_true'], metrics_resnet['y_pred'], class_names, 'ResNet50')\n\n# ƒê√°nh gi√° MobileNetV2\nprint(\"\\n\" + \"=\" * 70)\nprint(\"üü¢ ƒê√ÅNH GI√Å M√î H√åNH MOBILENETV2\")\nprint(\"=\" * 70)\nmetrics_mobilenet = evaluate_model(model_mobilenet, val_generator, 'MobileNetV2', class_names)\nplot_confusion_matrix(metrics_mobilenet['y_true'], metrics_mobilenet['y_pred'], class_names, 'MobileNetV2')\n\n# ƒê√°nh gi√° VGG19\nprint(\"\\n\" + \"=\" * 70)\nprint(\"üü£ ƒê√ÅNH GI√Å M√î H√åNH VGG19\")\nprint(\"=\" * 70)\nmetrics_vgg = evaluate_model(model_vgg, val_generator, 'VGG19', class_names)\nplot_confusion_matrix(metrics_vgg['y_true'], metrics_vgg['y_pred'], class_names, 'VGG19')"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## 6Ô∏è‚É£ So S√°nh M√¥ H√¨nh v√† K·∫øt Lu·∫≠n\n\nTrong ph·∫ßn n√†y, ch√∫ng ta s·∫Ω:\n- So s√°nh hi·ªáu su·∫•t c·ªßa 3 m√¥ h√¨nh\n- Ph√¢n t√≠ch ∆∞u nh∆∞·ª£c ƒëi·ªÉm c·ªßa t·ª´ng m√¥ h√¨nh\n- ƒê∆∞a ra k·∫øt lu·∫≠n v√† ƒë·ªÅ xu·∫•t m√¥ h√¨nh t·ªët nh·∫•t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# SO S√ÅNH HI·ªÜU SU·∫§T C√ÅC M√î H√åNH\n# ============================================\n\n# T·∫°o DataFrame so s√°nh\ncomparison_data = {\n    'M√¥ H√¨nh': ['ResNet50', 'MobileNetV2', 'VGG19'],\n    'Accuracy': [\n        metrics_resnet['accuracy'],\n        metrics_mobilenet['accuracy'],\n        metrics_vgg['accuracy']\n    ],\n    'Precision': [\n        metrics_resnet['precision'],\n        metrics_mobilenet['precision'],\n        metrics_vgg['precision']\n    ],\n    'Recall': [\n        metrics_resnet['recall'],\n        metrics_mobilenet['recall'],\n        metrics_vgg['recall']\n    ],\n    'F1-Score': [\n        metrics_resnet['f1_score'],\n        metrics_mobilenet['f1_score'],\n        metrics_vgg['f1_score']\n    ]\n}\n\ncomparison_df = pd.DataFrame(comparison_data)\n\n# ƒê·ªãnh d·∫°ng b·∫£ng\nprint(\"\\nüìä B·∫¢NG SO S√ÅNH HI·ªÜU SU·∫§T C√ÅC M√î H√åNH\")\nprint(\"=\" * 70)\nprint(comparison_df.to_string(index=False, float_format='{:.4f}'.format))\n\n# T√¨m m√¥ h√¨nh t·ªët nh·∫•t\nbest_model_idx = comparison_df['Accuracy'].idxmax()\nbest_model = comparison_df.loc[best_model_idx, 'M√¥ H√¨nh']\nbest_accuracy = comparison_df.loc[best_model_idx, 'Accuracy']\n\nprint(f\"\\nüèÜ M√î H√åNH T·ªêT NH·∫§T: {best_model}\")\nprint(f\"   Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# BI·ªÇU ƒê·ªí SO S√ÅNH C√ÅC M√î H√åNH\n# ============================================\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Bi·ªÉu ƒë·ªì c·ªôt so s√°nh c√°c metrics\nx = np.arange(len(comparison_df['M√¥ H√¨nh']))\nwidth = 0.2\n\nbars1 = axes[0].bar(x - 1.5*width, comparison_df['Accuracy'], width, label='Accuracy', color='#FF6B6B')\nbars2 = axes[0].bar(x - 0.5*width, comparison_df['Precision'], width, label='Precision', color='#4ECDC4')\nbars3 = axes[0].bar(x + 0.5*width, comparison_df['Recall'], width, label='Recall', color='#45B7D1')\nbars4 = axes[0].bar(x + 1.5*width, comparison_df['F1-Score'], width, label='F1-Score', color='#96CEB4')\n\naxes[0].set_xlabel('M√¥ H√¨nh', fontsize=12)\naxes[0].set_ylabel('Score', fontsize=12)\naxes[0].set_title('So S√°nh C√°c Metrics Gi·ªØa C√°c M√¥ H√¨nh', fontsize=14, fontweight='bold')\naxes[0].set_xticks(x)\naxes[0].set_xticklabels(comparison_df['M√¥ H√¨nh'])\naxes[0].legend()\naxes[0].set_ylim([0, 1.1])\naxes[0].grid(axis='y', alpha=0.3)\n\n# Th√™m gi√° tr·ªã tr√™n c·ªôt\nfor bars in [bars1, bars2, bars3, bars4]:\n    for bar in bars:\n        height = bar.get_height()\n        axes[0].annotate(f'{height:.2f}',\n                        xy=(bar.get_x() + bar.get_width() / 2, height),\n                        xytext=(0, 3),\n                        textcoords=\"offset points\",\n                        ha='center', va='bottom', fontsize=8)\n\n# Bi·ªÉu ƒë·ªì radar\ncategories = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\nN = len(categories)\nangles = [n / float(N) * 2 * np.pi for n in range(N)]\nangles += angles[:1]  # ƒê√≥ng v√≤ng tr√≤n\n\nax_radar = plt.subplot(1, 2, 2, projection='polar')\n\ncolors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\nfor i, model_name in enumerate(comparison_df['M√¥ H√¨nh']):\n    values = comparison_df.loc[i, ['Accuracy', 'Precision', 'Recall', 'F1-Score']].values.tolist()\n    values += values[:1]  # ƒê√≥ng v√≤ng tr√≤n\n    ax_radar.plot(angles, values, 'o-', linewidth=2, label=model_name, color=colors[i])\n    ax_radar.fill(angles, values, alpha=0.25, color=colors[i])\n\nax_radar.set_xticks(angles[:-1])\nax_radar.set_xticklabels(categories, fontsize=10)\nax_radar.set_title('Bi·ªÉu ƒê·ªì Radar So S√°nh', fontsize=14, fontweight='bold', y=1.08)\nax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n\nplt.tight_layout()\nplt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nüíæ Bi·ªÉu ƒë·ªì so s√°nh ƒë√£ ƒë∆∞·ª£c l∆∞u: model_comparison.png\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# PH√ÇN T√çCH K·∫æT QU·∫¢ V√Ä K·∫æT LU·∫¨N\n# ============================================\n\nprint(\"üìù PH√ÇN T√çCH K·∫æT QU·∫¢ V√Ä K·∫æT LU·∫¨N\")\nprint(\"=\" * 70)\n\n# Ph√¢n t√≠ch t·ª´ng m√¥ h√¨nh\nmodels_analysis = {\n    'ResNet50': {\n        'pros': [\n            'Ki·∫øn tr√∫c s√¢u v·ªõi skip connections gi√∫p h·ªçc ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p',\n            '·ªîn ƒë·ªãnh khi training v·ªõi nhi·ªÅu layer',\n            'Hi·ªáu su·∫•t t·ªët tr√™n nhi·ªÅu b√†i to√°n ph√¢n lo·∫°i ·∫£nh'\n        ],\n        'cons': [\n            'Y√™u c·∫ßu nhi·ªÅu t√†i nguy√™n t√≠nh to√°n',\n            'Th·ªùi gian inference l√¢u h∆°n MobileNet'\n        ]\n    },\n    'MobileNetV2': {\n        'pros': [\n            'Nh·∫π, nhanh, ph√π h·ª£p cho thi·∫øt b·ªã di ƒë·ªông',\n            'Depthwise Separable Convolutions gi·∫£m s·ªë parameters',\n            'Th·ªùi gian training v√† inference nhanh'\n        ],\n        'cons': [\n            'C√≥ th·ªÉ kh√¥ng ƒë·∫°t accuracy cao nh·∫•t v·ªõi d·ªØ li·ªáu ph·ª©c t·∫°p',\n            'Trade-off gi·ªØa t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c'\n        ]\n    },\n    'VGG19': {\n        'pros': [\n            'Ki·∫øn tr√∫c ƒë∆°n gi·∫£n, d·ªÖ hi·ªÉu v√† implement',\n            'ƒê·∫°t k·∫øt qu·∫£ t·ªët tr√™n nhi·ªÅu benchmark',\n            'Pretrained weights ch·∫•t l∆∞·ª£ng cao t·ª´ ImageNet'\n        ],\n        'cons': [\n            'Nhi·ªÅu parameters nh·∫•t (n·∫∑ng nh·∫•t)',\n            'T·ªën nhi·ªÅu b·ªô nh·ªõ v√† th·ªùi gian t√≠nh to√°n'\n        ]\n    }\n}\n\nfor model_name, analysis in models_analysis.items():\n    print(f\"\\nüîπ {model_name}:\")\n    print(\"   ∆Øu ƒëi·ªÉm:\")\n    for pro in analysis['pros']:\n        print(f\"      ‚úÖ {pro}\")\n    print(\"   Nh∆∞·ª£c ƒëi·ªÉm:\")\n    for con in analysis['cons']:\n        print(f\"      ‚ö†Ô∏è {con}\")\n\n# K·∫øt lu·∫≠n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"üéØ K·∫æT LU·∫¨N:\")\nprint(\"=\" * 70)\nprint(f\"\"\"\n1. M√î H√åNH T·ªêT NH·∫§T: {best_model} v·ªõi Accuracy: {best_accuracy*100:.2f}%\n\n2. SO S√ÅNH:\n   - ResNet50: Ph√π h·ª£p khi c·∫ßn ƒë·ªô ch√≠nh x√°c cao, c√≥ GPU m·∫°nh\n   - MobileNetV2: Ph√π h·ª£p cho ·ª©ng d·ª•ng th·ªùi gian th·ª±c, mobile\n   - VGG19: Baseline t·ªët, ki·∫øn tr√∫c c·ªï ƒëi·ªÉn ƒë√£ ƒë∆∞·ª£c ki·ªÉm ch·ª©ng\n\n3. ƒê·ªÄ XU·∫§T:\n   - V·ªõi ·ª©ng d·ª•ng th·ª±c t·∫ø: S·ª≠ d·ª•ng {best_model} ho·∫∑c MobileNetV2\n   - V·ªõi nghi√™n c·ª©u: So s√°nh th√™m v·ªõi EfficientNet, Vision Transformer\n   - ƒê·ªÉ tƒÉng accuracy: Fine-tune th√™m layers, tƒÉng data augmentation\n\"\"\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## 7Ô∏è‚É£ ƒê·ªÅ Xu·∫•t N√¢ng Cao v√† H∆∞·ªõng Ph√°t Tri·ªÉn\n\n### 7.1 C√°c k·ªπ thu·∫≠t n√¢ng cao c√≥ th·ªÉ √°p d·ª•ng\n\n1. **Grad-CAM (Gradient-weighted Class Activation Mapping)**\n   - Tr·ª±c quan h√≥a v√πng ·∫£nh m√† m√¥ h√¨nh t·∫≠p trung khi ƒë∆∞a ra d·ª± ƒëo√°n\n   - Gi√∫p gi·∫£i th√≠ch v√† debug m√¥ h√¨nh\n\n2. **EfficientNet**\n   - M√¥ h√¨nh hi·ªán ƒë·∫°i v·ªõi hi·ªáu su·∫•t state-of-the-art\n   - C√¢n b·∫±ng gi·ªØa ƒë·ªô s√¢u, chi·ªÅu r·ªông v√† ƒë·ªô ph√¢n gi·∫£i\n\n3. **Vision Transformer (ViT)**\n   - √Åp d·ª•ng ki·∫øn tr√∫c Transformer cho Computer Vision\n   - Hi·ªáu qu·∫£ v·ªõi d·ªØ li·ªáu l·ªõn\n\n4. **Data Augmentation n√¢ng cao**\n   - MixUp, CutMix, AutoAugment\n   - TƒÉng c∆∞·ªùng d·ªØ li·ªáu th√¥ng minh h∆°n\n\n5. **Ensemble Learning**\n   - K·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c\n   - Voting ho·∫∑c stacking"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# GRAD-CAM - GI·∫¢I TH√çCH D·ª∞ ƒêO√ÅN C·ª¶A M√î H√åNH\n# ============================================\n\ndef make_gradcam_heatmap(model, img_array, pred_index=None):\n    \"\"\"\n    T·∫°o Grad-CAM heatmap ƒë·ªÉ gi·∫£i th√≠ch d·ª± ƒëo√°n c·ªßa m√¥ h√¨nh\n    \n    Parameters:\n    - model: M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n    - img_array: ·∫¢nh ƒë·∫ßu v√†o (ƒë√£ ti·ªÅn x·ª≠ l√Ω)\n    - pred_index: Index c·ªßa class mu·ªën visualize (None = class c√≥ x√°c su·∫•t cao nh·∫•t)\n    \n    Returns:\n    - heatmap: Grad-CAM heatmap\n    \"\"\"\n    # L·∫•y layer convolution cu·ªëi c√πng\n    # T√¨m layer conv cu·ªëi trong base model\n    last_conv_layer = None\n    for layer in reversed(model.layers):\n        if 'conv' in layer.name.lower() or hasattr(layer, 'layers'):\n            if hasattr(layer, 'layers'):\n                for sub_layer in reversed(layer.layers):\n                    if 'conv' in sub_layer.name.lower():\n                        last_conv_layer_name = sub_layer.name\n                        last_conv_layer = layer.get_layer(last_conv_layer_name)\n                        break\n            else:\n                last_conv_layer = layer\n            if last_conv_layer is not None:\n                break\n    \n    if last_conv_layer is None:\n        print(\"Kh√¥ng t√¨m th·∫•y layer convolution!\")\n        return None\n    \n    # T·∫°o model ƒë·ªÉ l·∫•y gradient\n    grad_model = tf.keras.Model(\n        model.inputs,\n        [model.get_layer(model.layers[0].name).output, model.output]\n    )\n    \n    # T√≠nh gradient\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n    \n    # Gradient c·ªßa output class theo feature map\n    grads = tape.gradient(class_channel, conv_outputs)\n    \n    if grads is None:\n        return None\n    \n    # Global average pooling c·ªßa gradient\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n    \n    # Weight feature map v·ªõi gradient\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    \n    # Normalize heatmap\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    \n    return heatmap.numpy()\n\nprint(\"‚úÖ H√†m Grad-CAM ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")\nprint(\"\\nGrad-CAM gi√∫p tr·ª±c quan h√≥a v√πng ·∫£nh m√† m√¥ h√¨nh t·∫≠p trung khi ƒë∆∞a ra d·ª± ƒëo√°n.\")\nprint(\"ƒêi·ªÅu n√†y gi√∫p ch√∫ng ta hi·ªÉu v√† tin t∆∞·ªüng h∆°n v√†o quy·∫øt ƒë·ªãnh c·ªßa m√¥ h√¨nh.\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 7.2 H∆∞·ªõng ph√°t tri·ªÉn ti·∫øp theo\n\nüìå **C·∫£i thi·ªán m√¥ h√¨nh:**\n- Th·ª≠ nghi·ªám v·ªõi EfficientNet-B4, B5 (c√≥ th·ªÉ ƒë·∫°t >95% accuracy)\n- √Åp d·ª•ng Vision Transformer n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu\n- S·ª≠ d·ª•ng Cross-Validation ƒë·ªÉ ƒë√°nh gi√° ·ªïn ƒë·ªãnh h∆°n\n\nüìå **M·ªü r·ªông ·ª©ng d·ª•ng:**\n- X√¢y d·ª±ng API REST v·ªõi Flask/FastAPI ƒë·ªÉ deploy m√¥ h√¨nh\n- T·∫°o ·ª©ng d·ª•ng mobile v·ªõi TensorFlow Lite\n- Ph√°t tri·ªÉn giao di·ªán web ƒë·ªÉ ng∆∞·ªùi d√πng upload ·∫£nh v√† nh·∫≠n k·∫øt qu·∫£\n\nüìå **T√≠ch h·ª£p v·ªõi c√°c dataset kh√°c:**\n- PlantVillage Dataset: Dataset l·ªõn h∆°n v·ªõi nhi·ªÅu lo·∫°i b·ªánh c√¢y\n- K·∫øt h·ª£p v·ªõi d·ªØ li·ªáu th·ª±c t·∫ø thu th·∫≠p t·ª´ n√¥ng tr·∫°i\n\nüìå **T√†i nguy√™n tham kh·∫£o:**\n- [GitHub: Bean Leaf Classification](https://github.com/topics/bean-leaf-classification)\n- [Kaggle: Plant Disease Classification](https://www.kaggle.com/datasets)\n- [TensorFlow: Image Classification Tutorial](https://www.tensorflow.org/tutorials/images/classification)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# L∆ØU C√ÅC M√î H√åNH ƒê√É HU·∫§N LUY·ªÜN\n# ============================================\n\n# L∆∞u c√°c m√¥ h√¨nh\nprint(\"üíæ L∆ØU C√ÅC M√î H√åNH ƒê√É HU·∫§N LUY·ªÜN\")\nprint(\"=\" * 50)\n\ntry:\n    model_resnet.save('model_resnet50.keras')\n    print(\"‚úÖ ƒê√£ l∆∞u: model_resnet50.keras\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è L·ªói l∆∞u ResNet50: {e}\")\n\ntry:\n    model_mobilenet.save('model_mobilenetv2.keras')\n    print(\"‚úÖ ƒê√£ l∆∞u: model_mobilenetv2.keras\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è L·ªói l∆∞u MobileNetV2: {e}\")\n\ntry:\n    model_vgg.save('model_vgg19.keras')\n    print(\"‚úÖ ƒê√£ l∆∞u: model_vgg19.keras\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è L·ªói l∆∞u VGG19: {e}\")\n\nprint(\"\\nüìÅ C√°c m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u, c√≥ th·ªÉ load l·∫°i b·∫±ng:\")\nprint(\"   model = tf.keras.models.load_model('model_xxx.keras')\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 7.3 Demo D·ª± ƒêo√°n Tr√™n ·∫¢nh M·ªõi\n\nPh·∫ßn n√†y minh h·ªça c√°ch s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n tr√™n ·∫£nh m·ªõi."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# DEMO D·ª∞ ƒêO√ÅN TR√äN ·∫¢NH M·ªöI\n# ============================================\n\ndef predict_single_image(model, image_path, class_names, img_size=(224, 224)):\n    \"\"\"\n    D·ª± ƒëo√°n l·ªõp b·ªánh cho m·ªôt ·∫£nh l√° ƒë·∫≠u\n    \n    Parameters:\n    - model: M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n    - image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh\n    - class_names: Danh s√°ch t√™n c√°c l·ªõp\n    - img_size: K√≠ch th∆∞·ªõc ·∫£nh ƒë·∫ßu v√†o\n    \n    Returns:\n    - predicted_class: T√™n l·ªõp ƒë∆∞·ª£c d·ª± ƒëo√°n\n    - confidence: ƒê·ªô tin c·∫≠y c·ªßa d·ª± ƒëo√°n\n    \"\"\"\n    # ƒê·ªçc v√† ti·ªÅn x·ª≠ l√Ω ·∫£nh\n    img = Image.open(image_path)\n    img_resized = img.resize(img_size)\n    img_array = np.array(img_resized) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    \n    # D·ª± ƒëo√°n\n    predictions = model.predict(img_array, verbose=0)\n    predicted_idx = np.argmax(predictions[0])\n    confidence = predictions[0][predicted_idx]\n    predicted_class = class_names[predicted_idx]\n    \n    return predicted_class, confidence, predictions[0]\n\ndef visualize_prediction(image_path, predicted_class, confidence, all_probs, class_names):\n    \"\"\"Tr·ª±c quan h√≥a k·∫øt qu·∫£ d·ª± ƒëo√°n\"\"\"\n    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n    \n    # Hi·ªÉn th·ªã ·∫£nh\n    img = Image.open(image_path)\n    axes[0].imshow(img)\n    axes[0].axis('off')\n    \n    # M√†u s·∫Øc theo lo·∫°i b·ªánh\n    color_map = {\n        'healthy': '#4CAF50',\n        'angular_leaf_spot': '#FF9800', \n        'bean_rust': '#F44336'\n    }\n    title_color = color_map.get(predicted_class.lower(), '#2196F3')\n    \n    axes[0].set_title(f'D·ª± ƒëo√°n: {predicted_class}\\nƒê·ªô tin c·∫≠y: {confidence*100:.1f}%', \n                      fontsize=14, fontweight='bold', color=title_color)\n    \n    # Bi·ªÉu ƒë·ªì x√°c su·∫•t\n    colors = [color_map.get(c.lower(), '#2196F3') for c in class_names]\n    bars = axes[1].barh(class_names, all_probs, color=colors, edgecolor='black')\n    axes[1].set_xlabel('X√°c su·∫•t', fontsize=12)\n    axes[1].set_title('Ph√¢n b·ªë x√°c su·∫•t c√°c l·ªõp', fontsize=14, fontweight='bold')\n    axes[1].set_xlim([0, 1])\n    \n    # Th√™m nh√£n gi√° tr·ªã\n    for bar, prob in zip(bars, all_probs):\n        axes[1].text(prob + 0.02, bar.get_y() + bar.get_height()/2, \n                    f'{prob*100:.1f}%', va='center', fontsize=11)\n    \n    plt.tight_layout()\n    plt.savefig('prediction_demo.png', dpi=150, bbox_inches='tight')\n    plt.show()\n\nprint(\"‚úÖ H√†m demo d·ª± ƒëo√°n ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a!\")\nprint(\"\\nüìå C√°ch s·ª≠ d·ª•ng:\")\nprint(\"   predicted_class, confidence, probs = predict_single_image(model_resnet, 'path/to/image.jpg', class_names)\")\nprint(\"   visualize_prediction('path/to/image.jpg', predicted_class, confidence, probs, class_names)\")"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# DEMO: D·ª∞ ƒêO√ÅN TR√äN M·ªòT S·ªê ·∫¢NH T·ª™ T·∫¨P VALIDATION\n# ============================================\n\ndef demo_predictions(model, model_name, data_dir, class_names, num_samples=6):\n    \"\"\"Demo d·ª± ƒëo√°n tr√™n nhi·ªÅu ·∫£nh m·∫´u\"\"\"\n    \n    print(f\"\\nÔøΩÔøΩ DEMO D·ª∞ ƒêO√ÅN V·ªöI M√î H√åNH {model_name}\")\n    print(\"=\" * 60)\n    \n    # L·∫•y ng·∫´u nhi√™n m·ªôt s·ªë ·∫£nh t·ª´ m·ªói l·ªõp\n    sample_images = []\n    for class_name in class_names:\n        class_path = os.path.join(data_dir, class_name)\n        if os.path.exists(class_path):\n            images = [f for f in os.listdir(class_path) \n                     if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n            if images:\n                selected = random.sample(images, min(num_samples // len(class_names), len(images)))\n                for img in selected:\n                    sample_images.append((os.path.join(class_path, img), class_name))\n    \n    # D·ª± ƒëo√°n v√† hi·ªÉn th·ªã\n    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n    axes = axes.flatten()\n    \n    correct = 0\n    for i, (img_path, true_label) in enumerate(sample_images[:6]):\n        pred_class, confidence, probs = predict_single_image(model, img_path, class_names)\n        \n        # Hi·ªÉn th·ªã ·∫£nh\n        img = Image.open(img_path)\n        axes[i].imshow(img)\n        axes[i].axis('off')\n        \n        # Ki·ªÉm tra ƒë√∫ng/sai\n        is_correct = pred_class == true_label\n        if is_correct:\n            correct += 1\n            border_color = 'green'\n            result_text = '‚úì'\n        else:\n            border_color = 'red'\n            result_text = '‚úó'\n        \n        title = f\"Th·ª±c t·∫ø: {true_label}\\nD·ª± ƒëo√°n: {pred_class} ({confidence*100:.1f}%) {result_text}\"\n        axes[i].set_title(title, fontsize=10, color=border_color, fontweight='bold')\n        \n        # Th√™m border\n        for spine in axes[i].spines.values():\n            spine.set_edgecolor(border_color)\n            spine.set_linewidth(3)\n            spine.set_visible(True)\n    \n    plt.suptitle(f'Demo D·ª± ƒêo√°n - {model_name} ({correct}/{len(sample_images[:6])} ƒë√∫ng)', \n                 fontsize=16, fontweight='bold')\n    plt.tight_layout()\n    plt.savefig(f'demo_predictions_{model_name.lower()}.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    \n    print(f\"\\nüìä K·∫øt qu·∫£ demo: {correct}/{len(sample_images[:6])} d·ª± ƒëo√°n ƒë√∫ng\")\n\n# Ch·∫°y demo v·ªõi m√¥ h√¨nh t·ªët nh·∫•t\nprint(\"üéØ Ch·∫°y demo d·ª± ƒëo√°n v·ªõi c√°c m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán...\")\ndemo_predictions(model_resnet, 'ResNet50', VAL_DIR, class_names)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### 7.4 Xu·∫•t M√¥ H√¨nh v√† Tri·ªÉn Khai\n\nPh·∫ßn n√†y h∆∞·ªõng d·∫´n c√°ch xu·∫•t m√¥ h√¨nh ƒë·ªÉ tri·ªÉn khai trong ·ª©ng d·ª•ng th·ª±c t·∫ø."
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# XU·∫§T M√î H√åNH CHO TRI·ªÇN KHAI\n# ============================================\n\ndef export_model_for_deployment(model, model_name, export_dir='exported_models'):\n    \"\"\"\n    Xu·∫•t m√¥ h√¨nh ·ªü nhi·ªÅu ƒë·ªãnh d·∫°ng cho tri·ªÉn khai\n    \n    Parameters:\n    - model: M√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán\n    - model_name: T√™n m√¥ h√¨nh\n    - export_dir: Th∆∞ m·ª•c xu·∫•t\n    \"\"\"\n    import os\n    \n    os.makedirs(export_dir, exist_ok=True)\n    \n    print(f\"\\nüíæ XU·∫§T M√î H√åNH: {model_name}\")\n    print(\"=\" * 50)\n    \n    # 1. L∆∞u ƒë·ªãnh d·∫°ng Keras (.keras)\n    keras_path = os.path.join(export_dir, f'{model_name}.keras')\n    model.save(keras_path)\n    print(f\"‚úÖ ƒê√£ l∆∞u ƒë·ªãnh d·∫°ng Keras: {keras_path}\")\n    \n    # 2. L∆∞u ƒë·ªãnh d·∫°ng H5 (.h5) - t∆∞∆°ng th√≠ch v·ªõi nhi·ªÅu phi√™n b·∫£n\n    h5_path = os.path.join(export_dir, f'{model_name}.h5')\n    model.save(h5_path)\n    print(f\"‚úÖ ƒê√£ l∆∞u ƒë·ªãnh d·∫°ng H5: {h5_path}\")\n    \n    # 3. L∆∞u ƒë·ªãnh d·∫°ng SavedModel (cho TensorFlow Serving)\n    savedmodel_path = os.path.join(export_dir, f'{model_name}_savedmodel')\n    model.save(savedmodel_path, save_format='tf')\n    print(f\"‚úÖ ƒê√£ l∆∞u ƒë·ªãnh d·∫°ng SavedModel: {savedmodel_path}\")\n    \n    # 4. Chuy·ªÉn ƒë·ªïi sang TFLite (cho mobile)\n    try:\n        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n        tflite_model = converter.convert()\n        tflite_path = os.path.join(export_dir, f'{model_name}.tflite')\n        with open(tflite_path, 'wb') as f:\n            f.write(tflite_model)\n        print(f\"‚úÖ ƒê√£ l∆∞u ƒë·ªãnh d·∫°ng TFLite: {tflite_path}\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi TFLite: {e}\")\n    \n    print(f\"\\nüìÅ C√°c file ƒë√£ xu·∫•t trong th∆∞ m·ª•c: {export_dir}/\")\n    return export_dir\n\n# Xu·∫•t m√¥ h√¨nh t·ªët nh·∫•t\nprint(\"üì¶ Xu·∫•t m√¥ h√¨nh ƒë·ªÉ tri·ªÉn khai...\")\n# B·ªè comment d√≤ng d∆∞·ªõi ƒë·ªÉ xu·∫•t m√¥ h√¨nh\n# export_model_for_deployment(model_resnet, 'resnet50_bean_leaf')"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# T·ªîNG K·∫æT TH·ªêNG K√ä\n# ============================================\n\nprint(\"üìä T·ªîNG K·∫æT TH·ªêNG K√ä TO√ÄN B·ªò NOTEBOOK\")\nprint(\"=\" * 70)\n\n# Th√¥ng tin dataset\nprint(\"\\nüìÅ TH√îNG TIN DATASET:\")\nprint(f\"   T·ªïng s·ªë ·∫£nh train: {train_generator.samples}\")\nprint(f\"   T·ªïng s·ªë ·∫£nh validation: {val_generator.samples}\")\nprint(f\"   S·ªë l·ªõp ph√¢n lo·∫°i: {NUM_CLASSES}\")\nprint(f\"   K√≠ch th∆∞·ªõc ·∫£nh: {IMG_WIDTH}x{IMG_HEIGHT}\")\n\n# Th√¥ng tin hu·∫•n luy·ªán\nprint(\"\\n‚öôÔ∏è C·∫§U H√åNH HU·∫§N LUY·ªÜN:\")\nprint(f\"   Batch size: {BATCH_SIZE}\")\nprint(f\"   S·ªë epoch: {EPOCHS}\")\nprint(f\"   Learning rate: {LEARNING_RATE}\")\n\n# B·∫£ng t·ªïng k·∫øt c√°c m√¥ h√¨nh\nprint(\"\\nüèÜ K·∫æT QU·∫¢ C√ÅC M√î H√åNH:\")\nprint(\"-\" * 70)\nprint(f\"{'M√¥ h√¨nh':<15} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12}\")\nprint(\"-\" * 70)\n\nmodels_results = [\n    ('ResNet50', metrics_resnet),\n    ('MobileNetV2', metrics_mobilenet),\n    ('VGG19', metrics_vgg)\n]\n\nbest_acc = 0\nbest_model_name = ''\nfor name, metrics in models_results:\n    print(f\"{name:<15} {metrics['accuracy']:<12.4f} {metrics['precision']:<12.4f} {metrics['recall']:<12.4f} {metrics['f1_score']:<12.4f}\")\n    if metrics['accuracy'] > best_acc:\n        best_acc = metrics['accuracy']\n        best_model_name = name\n\nprint(\"-\" * 70)\nprint(f\"\\nü•á M√î H√åNH T·ªêT NH·∫§T: {best_model_name} v·ªõi Accuracy = {best_acc*100:.2f}%\")\n\n# L∆∞u k·∫øt qu·∫£ v√†o file CSV\nresults_df = pd.DataFrame({\n    'Model': [name for name, _ in models_results],\n    'Accuracy': [m['accuracy'] for _, m in models_results],\n    'Precision': [m['precision'] for _, m in models_results],\n    'Recall': [m['recall'] for _, m in models_results],\n    'F1-Score': [m['f1_score'] for _, m in models_results]\n})\nresults_df.to_csv('model_results.csv', index=False)\nprint(\"\\nüíæ K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o: model_results.csv\")"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "---\n\n## üìã T·ªïng K·∫øt\n\n### Nh·ªØng g√¨ ƒë√£ th·ª±c hi·ªán trong notebook n√†y:\n\n1. ‚úÖ **Nh·∫≠p th∆∞ vi·ªán v√† t·∫£i d·ªØ li·ªáu** - S·ª≠ d·ª•ng TensorFlow/Keras v√† c√°c th∆∞ vi·ªán h·ªó tr·ª£\n\n2. ‚úÖ **Kh√°m ph√° d·ªØ li·ªáu (EDA)** - Ph√¢n t√≠ch s·ªë l∆∞·ª£ng ·∫£nh, k√≠ch th∆∞·ªõc, ph√¢n b·ªë c√°c l·ªõp v·ªõi bi·ªÉu ƒë·ªì tr·ª±c quan\n\n3. ‚úÖ **Ti·ªÅn x·ª≠ l√Ω ·∫£nh** - Resize, chu·∫©n h√≥a, Data Augmentation ƒë·ªÉ tƒÉng c∆∞·ªùng d·ªØ li·ªáu\n\n4. ‚úÖ **X√¢y d·ª±ng m√¥ h√¨nh Deep Learning** - Transfer Learning v·ªõi 3 m√¥ h√¨nh:\n   - ResNet50\n   - MobileNetV2\n   - VGG19\n\n5. ‚úÖ **ƒê√°nh gi√° v√† ph√¢n t√≠ch k·∫øt qu·∫£** - Accuracy, Precision, Recall, F1-Score, Confusion Matrix\n\n6. ‚úÖ **So s√°nh m√¥ h√¨nh** - B·∫£ng so s√°nh v√† bi·ªÉu ƒë·ªì radar\n\n7. ‚úÖ **ƒê·ªÅ xu·∫•t n√¢ng cao** - Grad-CAM, EfficientNet, Vision Transformer, h∆∞·ªõng ph√°t tri·ªÉn\n\n---\n\n### üìö T√†i li·ªáu tham kh·∫£o\n\n1. [Kaggle Dataset: Bean Leaf Lesions Classification](https://www.kaggle.com/datasets/marquis03/bean-leaf-lesions-classification)\n2. [TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)\n3. [Keras Applications](https://keras.io/api/applications/)\n4. [GitHub: Plant Disease Classification Projects](https://github.com/topics/plant-disease-classification)\n\n---\n\n### üë®‚Äçüíª Th√¥ng tin\n\n- **Ng√¥n ng·ªØ:** Python 3.10+\n- **Framework:** TensorFlow/Keras\n- **M·ª•c ƒë√≠ch:** B√†i t·∫≠p l·ªõn m√¥n Khai Ph√° D·ªØ Li·ªáu\n\n---\n\n**¬© 2024 - Bean Leaf Lesions Classification Project**"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================\n# TH√îNG TIN C√ÄI ƒê·∫∂T\n# ============================================\n\nprint(\"üì¶ C√ÅC TH∆Ø VI·ªÜN C·∫¶N C√ÄI ƒê·∫∂T:\")\nprint(\"=\" * 50)\nprint(\"\"\"\n# File: requirements.txt\n\n# Core Data Science\nnumpy>=1.21.0\npandas>=1.3.0\n\n# Visualization\nmatplotlib>=3.4.0\nseaborn>=0.11.0\n\n# Deep Learning\ntensorflow>=2.10.0\n\n# Image Processing\nPillow>=8.0.0\n\n# Machine Learning Utilities\nscikit-learn>=0.24.0\n\n# Kaggle API (ƒë·ªÉ t·∫£i dataset)\nkaggle>=1.5.12\n\"\"\")\n\nprint(\"\\nüíª C√ÅCH C√ÄI ƒê·∫∂T:\")\nprint(\"   pip install -r requirements.txt\")\n\nprint(\"\\nüöÄ C√ÅCH CH·∫†Y NOTEBOOK:\")\nprint(\"   1. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán: pip install -r requirements.txt\")\nprint(\"   2. T·∫£i dataset: python download_dataset.py\")\nprint(\"   3. M·ªü notebook: jupyter notebook bean_leaf_classification.ipynb\")\nprint(\"   4. Ch·∫°y t·ª´ng cell theo th·ª© t·ª±\")"
    }
  ]
}