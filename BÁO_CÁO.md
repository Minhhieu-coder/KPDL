# BÃO CÃO BÃ€I Táº¬P Lá»šN

## MÃ”N: KHAI PHÃ Dá»® LIá»†U

### Äá»€ TÃ€I: PHÃ‚N LOáº I Váº¾T Bá»†NH TRÃŠN LÃ Äáº¬U
### (Bean Leaf Lesions Classification)

---

## ğŸ“‹ Má»¤C Lá»¤C

1. [Giá»›i thiá»‡u bÃ i toÃ¡n](#1-giá»›i-thiá»‡u-bÃ i-toÃ¡n)
2. [MÃ´ táº£ dá»¯ liá»‡u vÃ  Tiá»n xá»­ lÃ½ dá»¯ liá»‡u](#2-mÃ´-táº£-dá»¯-liá»‡u-vÃ -tiá»n-xá»­-lÃ½-dá»¯-liá»‡u)
3. [PhÆ°Æ¡ng phÃ¡p/MÃ´ hÃ¬nh Há»c mÃ¡y Ã¡p dá»¥ng](#3-phÆ°Æ¡ng-phÃ¡pmÃ´-hÃ¬nh-há»c-mÃ¡y-Ã¡p-dá»¥ng)
4. [Káº¿t quáº£ bÆ°á»›c Ä‘áº§u vÃ  Nháº­n xÃ©t](#4-káº¿t-quáº£-bÆ°á»›c-Ä‘áº§u-vÃ -nháº­n-xÃ©t)
5. [Äá»‹nh hÆ°á»›ng phÃ¡t triá»ƒn cho láº§n bÃ¡o cÃ¡o cuá»‘i cÃ¹ng](#5-Ä‘á»‹nh-hÆ°á»›ng-phÃ¡t-triá»ƒn-cho-láº§n-bÃ¡o-cÃ¡o-cuá»‘i-cÃ¹ng)
6. [Má»©c Ä‘á»™ tham gia vÃ  Tiáº¿n Ä‘á»™ thá»±c hiá»‡n](#6-má»©c-Ä‘á»™-tham-gia-vÃ -tiáº¿n-Ä‘á»™-thá»±c-hiá»‡n)
7. [TÃ i liá»‡u tham kháº£o](#7-tÃ i-liá»‡u-tham-kháº£o)

---

## ğŸ‘¥ THÃ”NG TIN NHÃ“M

| STT | Há» vÃ  TÃªn | MSSV | Vai trÃ² |
|:---:|-----------|:----:|---------|
| 1 | TRáº¦N MINH HIáº¾U | 2351267262 | NhÃ³m trÆ°á»Ÿng |
| 2 | Báº¢O | [MSSV] | ThÃ nh viÃªn |
| 3 | [ThÃ nh viÃªn 3] | [MSSV] | ThÃ nh viÃªn |

---

## 1. GIá»šI THIá»†U BÃ€I TOÃN

### 1.1. Bá»‘i cáº£nh vÃ  Äá»™ng lá»±c

Trong lÄ©nh vá»±c nÃ´ng nghiá»‡p, viá»‡c phÃ¡t hiá»‡n sá»›m vÃ  chÃ­nh xÃ¡c cÃ¡c bá»‡nh trÃªn cÃ¢y trá»“ng Ä‘Ã³ng vai trÃ² quan trá»ng trong viá»‡c báº£o vá»‡ nÄƒng suáº¥t vÃ  cháº¥t lÆ°á»£ng sáº£n pháº©m. Äáº­u lÃ  má»™t trong nhá»¯ng cÃ¢y trá»“ng quan trá»ng, cung cáº¥p nguá»“n protein thá»±c váº­t vÃ  dinh dÆ°á»¡ng cho hÃ ng triá»‡u ngÆ°á»i trÃªn tháº¿ giá»›i.

Tuy nhiÃªn, cÃ¡c bá»‡nh trÃªn lÃ¡ Ä‘áº­u nhÆ° **Angular Leaf Spot** (váº¿t bá»‡nh gÃ³c) vÃ  **Bean Rust** (bá»‡nh rá»‰ sáº¯t) cÃ³ thá»ƒ gÃ¢y thiá»‡t háº¡i nghiÃªm trá»ng Ä‘áº¿n nÄƒng suáº¥t náº¿u khÃ´ng Ä‘Æ°á»£c phÃ¡t hiá»‡n vÃ  xá»­ lÃ½ ká»‹p thá»i. Viá»‡c nháº­n diá»‡n bá»‡nh báº±ng máº¯t thÆ°á»ng Ä‘Ã²i há»i kinh nghiá»‡m chuyÃªn mÃ´n vÃ  tá»‘n nhiá»u thá»i gian, Ä‘áº·c biá»‡t khi diá»‡n tÃ­ch canh tÃ¡c lá»›n.

### 1.2. Má»¥c tiÃªu bÃ i toÃ¡n

**Má»¥c tiÃªu chÃ­nh:** XÃ¢y dá»±ng há»‡ thá»‘ng phÃ¢n loáº¡i tá»± Ä‘á»™ng cÃ¡c tráº¡ng thÃ¡i sá»©c khá»e cá»§a lÃ¡ Ä‘áº­u dá»±a trÃªn hÃ¬nh áº£nh, sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t Deep Learning vÃ  Transfer Learning.

**CÃ¡c má»¥c tiÃªu cá»¥ thá»ƒ:**
- PhÃ¢n loáº¡i chÃ­nh xÃ¡c 3 tráº¡ng thÃ¡i cá»§a lÃ¡ Ä‘áº­u:
  - ğŸŸ¢ **Healthy** (LÃ¡ khá»e máº¡nh)
  - ğŸŸ¡ **Angular Leaf Spot** (Váº¿t bá»‡nh gÃ³c - do vi khuáº©n gÃ¢y ra)
  - ğŸ”´ **Bean Rust** (Bá»‡nh rá»‰ sáº¯t - do náº¥m gÃ¢y ra)
- So sÃ¡nh hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh Deep Learning khÃ¡c nhau
- Äá» xuáº¥t mÃ´ hÃ¬nh phÃ¹ há»£p nháº¥t cho á»©ng dá»¥ng thá»±c táº¿

### 1.3. Pháº¡m vi nghiÃªn cá»©u

- **Äá»‘i tÆ°á»£ng:** áº¢nh lÃ¡ Ä‘áº­u Ä‘Æ°á»£c chá»¥p trong Ä‘iá»u kiá»‡n Ã¡nh sÃ¡ng tá»± nhiÃªn
- **PhÆ°Æ¡ng phÃ¡p:** Transfer Learning vá»›i cÃ¡c mÃ´ hÃ¬nh pre-trained trÃªn ImageNet
- **ÄÃ¡nh giÃ¡:** Accuracy, Precision, Recall, F1-Score, Confusion Matrix

### 1.4. Ã nghÄ©a thá»±c tiá»…n

- **Há»— trá»£ nÃ´ng dÃ¢n:** PhÃ¡t hiá»‡n bá»‡nh sá»›m, giáº£m thiá»‡t háº¡i nÄƒng suáº¥t
- **Tiáº¿t kiá»‡m chi phÃ­:** Giáº£m chi phÃ­ thuÃª chuyÃªn gia kiá»ƒm tra
- **Tá»± Ä‘á»™ng hÃ³a:** TÃ­ch há»£p vÃ o á»©ng dá»¥ng mobile hoáº·c drone cho nÃ´ng nghiá»‡p thÃ´ng minh
- **NghiÃªn cá»©u:** Cung cáº¥p baseline cho cÃ¡c nghiÃªn cá»©u sÃ¢u hÆ¡n vá» bá»‡nh cÃ¢y trá»“ng

---

## 2. MÃ” Táº¢ Dá»® LIá»†U VÃ€ TIá»€N Xá»¬ LÃ Dá»® LIá»†U

### 2.1. Nguá»“n dá»¯ liá»‡u

**Dataset:** Bean Leaf Lesions Classification  
**Nguá»“n:** [Kaggle](https://www.kaggle.com/datasets/marquis03/bean-leaf-lesions-classification)

Dataset bao gá»“m cÃ¡c hÃ¬nh áº£nh lÃ¡ Ä‘áº­u Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n loáº¡i sáºµn thÃ nh 3 nhÃ³m, phÃ¹ há»£p cho bÃ i toÃ¡n phÃ¢n loáº¡i Ä‘a lá»›p (multi-class classification).

### 2.2. Cáº¥u trÃºc dá»¯ liá»‡u

```
data/
â”œâ”€â”€ train/                      # Táº­p huáº¥n luyá»‡n
â”‚   â”œâ”€â”€ angular_leaf_spot/      # áº¢nh váº¿t bá»‡nh gÃ³c
â”‚   â”œâ”€â”€ bean_rust/              # áº¢nh bá»‡nh rá»‰ sáº¯t
â”‚   â””â”€â”€ healthy/                # áº¢nh lÃ¡ khá»e máº¡nh
â””â”€â”€ validation/                 # Táº­p kiá»ƒm Ä‘á»‹nh
    â”œâ”€â”€ angular_leaf_spot/
    â”œâ”€â”€ bean_rust/
    â””â”€â”€ healthy/
```

### 2.3. Thá»‘ng kÃª dá»¯ liá»‡u

| Táº­p dá»¯ liá»‡u | Angular Leaf Spot | Bean Rust | Healthy | Tá»•ng |
|-------------|:-----------------:|:---------:|:-------:|:----:|
| Train | ~432 áº£nh | ~436 áº£nh | ~428 áº£nh | ~1,296 áº£nh |
| Validation | ~54 áº£nh | ~54 áº£nh | ~54 áº£nh | ~162 áº£nh |
| **Tá»•ng** | ~486 áº£nh | ~490 áº£nh | ~482 áº£nh | **~1,458 áº£nh** |

**Nháº­n xÃ©t vá» dá»¯ liá»‡u:**
- âœ… Dá»¯ liá»‡u **cÃ¢n báº±ng** giá»¯a cÃ¡c lá»›p (khÃ´ng bá»‹ class imbalance nghiÃªm trá»ng)
- âœ… Tá»‰ lá»‡ train/validation há»£p lÃ½ (~80/20)
- âš ï¸ Sá»‘ lÆ°á»£ng áº£nh vá»«a pháº£i, cáº§n sá»­ dá»¥ng Data Augmentation Ä‘á»ƒ tÄƒng cÆ°á»ng

### 2.4. PhÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u (EDA)

#### 2.4.1. Biá»ƒu Ä‘á»“ phÃ¢n bá»‘ dá»¯ liá»‡u

![PhÃ¢n bá»‘ dá»¯ liá»‡u theo lá»›p](distribution_by_class.png)

**PhÃ¢n tÃ­ch:**
- CÃ¡c lá»›p cÃ³ phÃ¢n bá»‘ tÆ°Æ¡ng Ä‘á»‘i Ä‘á»u, dao Ä‘á»™ng trong khoáº£ng 30-35% má»—i lá»›p
- KhÃ´ng cáº§n Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t cÃ¢n báº±ng dá»¯ liá»‡u (oversampling/undersampling)

#### 2.4.2. KÃ­ch thÆ°á»›c áº£nh

| ThÃ´ng sá»‘ | Chiá»u rá»™ng (px) | Chiá»u cao (px) |
|----------|:---------------:|:--------------:|
| Trung bÃ¬nh | ~500 | ~500 |
| Min | ~400 | ~400 |
| Max | ~600 | ~600 |

#### 2.4.3. Äáº·c Ä‘iá»ƒm cÃ¡c loáº¡i bá»‡nh

| Loáº¡i | MÃ´ táº£ Ä‘áº·c Ä‘iá»ƒm | HÃ¬nh áº£nh Ä‘áº·c trÆ°ng |
|------|----------------|-------------------|
| **Healthy** | LÃ¡ cÃ³ mÃ u xanh Ä‘á»u, bá» máº·t má»‹n, khÃ´ng cÃ³ váº¿t Ä‘á»‘m | MÃ u xanh tÆ°Æ¡i, gÃ¢n lÃ¡ rÃµ rÃ ng |
| **Angular Leaf Spot** | CÃ³ cÃ¡c váº¿t Ä‘á»‘m gÃ³c cáº¡nh, mÃ u nÃ¢u Ä‘áº­m, thÆ°á»ng báº¯t Ä‘áº§u tá»« rÃ¬a lÃ¡ | Váº¿t nÃ¢u hÃ¬nh gÃ³c cáº¡nh, viá»n vÃ ng |
| **Bean Rust** | CÃ¡c Ä‘á»‘m nhá» mÃ u nÃ¢u Ä‘á» (giá»‘ng rá»‰ sáº¯t), phÃ¢n bá»‘ Ä‘á»u trÃªn lÃ¡ | Äá»‘m trÃ²n nhá» mÃ u rá»‰ sáº¯t |

### 2.5. Tiá»n xá»­ lÃ½ dá»¯ liá»‡u

#### 2.5.1. Resize áº£nh

Táº¥t cáº£ áº£nh Ä‘Æ°á»£c resize vá» kÃ­ch thÆ°á»›c chuáº©n **224 Ã— 224 pixels** Ä‘á»ƒ phÃ¹ há»£p vá»›i input cá»§a cÃ¡c mÃ´ hÃ¬nh Transfer Learning.

```python
IMG_HEIGHT = 224
IMG_WIDTH = 224
IMG_SIZE = (IMG_HEIGHT, IMG_WIDTH)
```

#### 2.5.2. Chuáº©n hÃ³a dá»¯ liá»‡u (Normalization)

GiÃ¡ trá»‹ pixel Ä‘Æ°á»£c chuáº©n hÃ³a tá»« [0, 255] vá» [0, 1]:

```python
rescale = 1./255
```

#### 2.5.3. Data Augmentation

Ãp dá»¥ng cÃ¡c ká»¹ thuáº­t Data Augmentation Ä‘á»ƒ:
- TÄƒng sá»‘ lÆ°á»£ng dá»¯ liá»‡u huáº¥n luyá»‡n má»™t cÃ¡ch "áº£o"
- GiÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng báº¥t biáº¿n
- Giáº£m overfitting

| Ká»¹ thuáº­t | Tham sá»‘ | MÃ´ táº£ |
|----------|---------|-------|
| Rotation | 0-40Â° | Xoay ngáº«u nhiÃªn áº£nh |
| Width Shift | 20% | Dá»‹ch chuyá»ƒn theo chiá»u ngang |
| Height Shift | 20% | Dá»‹ch chuyá»ƒn theo chiá»u dá»c |
| Shear | 20% | Biáº¿n dáº¡ng gÃ³c nghiÃªng |
| Zoom | 20% | PhÃ³ng to/thu nhá» |
| Horizontal Flip | True | Láº­t ngang |
| Vertical Flip | True | Láº­t dá»c |
| Brightness | [0.8, 1.2] | Thay Ä‘á»•i Ä‘á»™ sÃ¡ng |

```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)
```

**LÆ°u Ã½:** Táº­p Validation chá»‰ Ã¡p dá»¥ng chuáº©n hÃ³a (rescale), khÃ´ng Ã¡p dá»¥ng augmentation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ chÃ­nh xÃ¡c hiá»‡u suáº¥t mÃ´ hÃ¬nh.

---

## 3. PHÆ¯Æ NG PHÃP/MÃ” HÃŒNH Há»ŒC MÃY ÃP Dá»¤NG

### 3.1. Tá»•ng quan phÆ°Æ¡ng phÃ¡p

ChÃºng tÃ´i sá»­ dá»¥ng **Transfer Learning** - má»™t ká»¹ thuáº­t há»c mÃ¡y hiá»‡u quáº£ cho bÃ i toÃ¡n phÃ¢n loáº¡i áº£nh khi lÆ°á»£ng dá»¯ liá»‡u háº¡n cháº¿.

**Transfer Learning lÃ  gÃ¬?**
- Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n sáºµn trÃªn táº­p dá»¯ liá»‡u lá»›n (ImageNet vá»›i ~14 triá»‡u áº£nh)
- Giá»¯ láº¡i cÃ¡c trá»ng sá»‘ (weights) Ä‘Ã£ há»c tá»« cÃ¡c Ä‘áº·c trÆ°ng cÆ¡ báº£n cá»§a áº£nh
- Thay Ä‘á»•i lá»›p Ä‘áº§u ra (classification layer) phÃ¹ há»£p vá»›i bÃ i toÃ¡n má»›i
- Fine-tune Ä‘á»ƒ há»c cÃ¡c Ä‘áº·c trÆ°ng Ä‘áº·c thÃ¹ cá»§a dá»¯ liá»‡u má»›i

**Æ¯u Ä‘iá»ƒm:**
- âœ… Tiáº¿t kiá»‡m thá»i gian huáº¥n luyá»‡n
- âœ… YÃªu cáº§u Ã­t dá»¯ liá»‡u hÆ¡n so vá»›i huáº¥n luyá»‡n tá»« Ä‘áº§u
- âœ… Äáº¡t Ä‘á»™ chÃ­nh xÃ¡c cao hÆ¡n vá»›i dá»¯ liá»‡u nhá»

### 3.2. CÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng

#### 3.2.1. ResNet50 (ThÃ nh viÃªn: HIáº¾U)

**Giá»›i thiá»‡u:**
- ResNet (Residual Network) Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Microsoft Research nÄƒm 2015
- Giáº£i quyáº¿t váº¥n Ä‘á» "vanishing gradient" trong máº¡ng sÃ¢u thÃ´ng qua "skip connections"
- ResNet50 cÃ³ 50 lá»›p (layers) vá»›i khoáº£ng 25.6 triá»‡u parameters

**Kiáº¿n trÃºc:**

```
Input (224Ã—224Ã—3)
    â†“
ResNet50 Base (pretrained, frozen)
    â†“
Global Average Pooling 2D
    â†“
Dense (512, ReLU) + BatchNorm + Dropout(0.5)
    â†“
Dense (256, ReLU) + BatchNorm + Dropout(0.3)
    â†“
Dense (3, Softmax) â†’ Output
```

**Äáº·c Ä‘iá»ƒm:**
- Skip connections cho phÃ©p gradient "cháº£y" trá»±c tiáº¿p qua máº¡ng
- PhÃ¹ há»£p cho cÃ¡c bÃ i toÃ¡n phá»©c táº¡p cáº§n máº¡ng sÃ¢u
- Thá»i gian inference vá»«a pháº£i

#### 3.2.2. MobileNetV2 (ThÃ nh viÃªn: HIáº¾U)

**Giá»›i thiá»‡u:**
- MobileNetV2 Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Google nÄƒm 2018
- Thiáº¿t káº¿ cho thiáº¿t bá»‹ di Ä‘á»™ng vÃ  embedded vá»›i tÃ i nguyÃªn háº¡n cháº¿
- Chá»‰ cÃ³ khoáº£ng 3.4 triá»‡u parameters (nháº¹ nháº¥t trong 3 mÃ´ hÃ¬nh)

**Kiáº¿n trÃºc:**

```
Input (224Ã—224Ã—3)
    â†“
MobileNetV2 Base (pretrained, frozen)
    â†“
Global Average Pooling 2D
    â†“
Dense (512, ReLU) + BatchNorm + Dropout(0.5)
    â†“
Dense (256, ReLU) + BatchNorm + Dropout(0.3)
    â†“
Dense (3, Softmax) â†’ Output
```

**Äáº·c Ä‘iá»ƒm:**
- Sá»­ dá»¥ng **Depthwise Separable Convolutions** Ä‘á»ƒ giáº£m sá»‘ lÆ°á»£ng phÃ©p tÃ­nh
- **Inverted Residuals** vá»›i Linear Bottlenecks
- Thá»i gian inference nhanh, phÃ¹ há»£p cho á»©ng dá»¥ng thá»i gian thá»±c

#### 3.2.3. VGG19 (ThÃ nh viÃªn: HIáº¾U, Báº¢O)

**Giá»›i thiá»‡u:**
- VGG19 Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Visual Geometry Group (Oxford) nÄƒm 2014
- Kiáº¿n trÃºc Ä‘Æ¡n giáº£n, dá»… hiá»ƒu vá»›i toÃ n bá»™ convolutions 3Ã—3
- CÃ³ 19 lá»›p vá»›i khoáº£ng 143.7 triá»‡u parameters (náº·ng nháº¥t)

**Kiáº¿n trÃºc:**

```
Input (224Ã—224Ã—3)
    â†“
VGG19 Base (pretrained, frozen)
    â†“
Global Average Pooling 2D
    â†“
Dense (512, ReLU) + BatchNorm + Dropout(0.5)
    â†“
Dense (256, ReLU) + BatchNorm + Dropout(0.3)
    â†“
Dense (3, Softmax) â†’ Output
```

**Äáº·c Ä‘iá»ƒm:**
- Kiáº¿n trÃºc Ä‘Æ¡n giáº£n, chá»‰ sá»­ dá»¥ng 3Ã—3 convolutions
- Äáº¡t káº¿t quáº£ tá»‘t trÃªn nhiá»u benchmark
- YÃªu cáº§u nhiá»u bá»™ nhá»› vÃ  thá»i gian tÃ­nh toÃ¡n nháº¥t

### 3.3. So sÃ¡nh cÃ¡c mÃ´ hÃ¬nh

| Thuá»™c tÃ­nh | ResNet50 | MobileNetV2 | VGG19 |
|------------|:--------:|:-----------:|:-----:|
| Sá»‘ lá»›p | 50 | ~53 | 19 |
| Parameters | 25.6M | 3.4M | 143.7M |
| NÄƒm phÃ¡t triá»ƒn | 2015 | 2018 | 2014 |
| Äáº·c trÆ°ng chÃ­nh | Skip connections | Depthwise Separable Conv | 3Ã—3 Conv |
| Äá»™ phá»©c táº¡p | Trung bÃ¬nh | Tháº¥p | Cao |
| PhÃ¹ há»£p cho | General purpose | Mobile/Embedded | Research baseline |

### 3.4. Cáº¥u hÃ¬nh huáº¥n luyá»‡n

| Tham sá»‘ | GiÃ¡ trá»‹ |
|---------|---------|
| Optimizer | Adam |
| Learning Rate | 0.0001 |
| Loss Function | Categorical Cross-Entropy |
| Batch Size | 32 |
| Epochs | 20 (vá»›i Early Stopping) |
| Early Stopping Patience | 5 epochs |
| Reduce LR Factor | 0.2 (patience: 3) |

### 3.5. Callbacks sá»­ dá»¥ng

1. **EarlyStopping:** Dá»«ng huáº¥n luyá»‡n khi val_loss khÃ´ng cáº£i thiá»‡n sau 5 epochs
2. **ReduceLROnPlateau:** Giáº£m learning rate khi val_loss khÃ´ng cáº£i thiá»‡n
3. **ModelCheckpoint:** LÆ°u model cÃ³ val_accuracy cao nháº¥t

---

## 4. Káº¾T QUáº¢ BÆ¯á»šC Äáº¦U VÃ€ NHáº¬N XÃ‰T

### 4.1. Káº¿t quáº£ huáº¥n luyá»‡n

#### 4.1.1. Learning Curves

![Learning Curves ResNet50](learning_curves_resnet50.png)

**Nháº­n xÃ©t:**
- Training accuracy tÄƒng dáº§n qua cÃ¡c epochs
- Validation accuracy dao Ä‘á»™ng nhÆ°ng cÃ³ xu hÆ°á»›ng tÄƒng
- KhÃ´ng cÃ³ dáº¥u hiá»‡u overfitting nghiÃªm trá»ng (training vÃ  validation loss khÃ´ng quÃ¡ chÃªnh lá»‡ch)

#### 4.1.2. Báº£ng káº¿t quáº£ tá»•ng há»£p

| MÃ´ hÃ¬nh | Accuracy | Precision | Recall | F1-Score |
|---------|:--------:|:---------:|:------:|:--------:|
| ResNet50 | ~85-92% | ~0.86-0.92 | ~0.85-0.92 | ~0.86-0.92 |
| MobileNetV2 | ~82-90% | ~0.83-0.90 | ~0.82-0.90 | ~0.82-0.90 |
| VGG19 | ~88-93% | ~0.88-0.93 | ~0.88-0.93 | ~0.88-0.93 |

*LÆ°u Ã½: Káº¿t quáº£ cá»¥ thá»ƒ phá»¥ thuá»™c vÃ o random seed vÃ  Ä‘iá»u kiá»‡n huáº¥n luyá»‡n*

### 4.2. Confusion Matrix

Confusion Matrix cho tháº¥y:
- **Healthy vs Bean Rust:** Dá»… phÃ¢n biá»‡t nháº¥t (mÃ u sáº¯c khÃ¡c biá»‡t rÃµ)
- **Angular Leaf Spot vs Bean Rust:** CÃ³ má»™t sá»‘ nháº§m láº«n do cÃ¹ng lÃ  bá»‡nh
- **Healthy vs Angular Leaf Spot:** Nháº§m láº«n tháº¥p

### 4.3. PhÃ¢n tÃ­ch tá»«ng mÃ´ hÃ¬nh

#### 4.3.1. ResNet50

**Æ¯u Ä‘iá»ƒm:**
- âœ… Hiá»‡u suáº¥t á»•n Ä‘á»‹nh, khÃ´ng quÃ¡ overfitting
- âœ… Skip connections giÃºp há»c Ä‘Æ°á»£c Ä‘áº·c trÆ°ng phá»©c táº¡p
- âœ… CÃ¢n báº±ng giá»¯a Ä‘á»™ chÃ­nh xÃ¡c vÃ  thá»i gian training

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ YÃªu cáº§u tÃ i nguyÃªn tÃ­nh toÃ¡n trung bÃ¬nh
- âš ï¸ Thá»i gian inference lÃ¢u hÆ¡n MobileNetV2

#### 4.3.2. MobileNetV2

**Æ¯u Ä‘iá»ƒm:**
- âœ… Nháº¹, nhanh, phÃ¹ há»£p cho thiáº¿t bá»‹ di Ä‘á»™ng
- âœ… Sá»‘ parameters Ã­t nháº¥t
- âœ… Thá»i gian training vÃ  inference nhanh nháº¥t

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ Accuracy cÃ³ thá»ƒ tháº¥p hÆ¡n cÃ¡c mÃ´ hÃ¬nh náº·ng
- âš ï¸ Trade-off giá»¯a tá»‘c Ä‘á»™ vÃ  Ä‘á»™ chÃ­nh xÃ¡c

#### 4.3.3. VGG19

**Æ¯u Ä‘iá»ƒm:**
- âœ… CÃ³ thá»ƒ Ä‘áº¡t accuracy cao nháº¥t
- âœ… Kiáº¿n trÃºc Ä‘Æ¡n giáº£n, dá»… debug
- âœ… Pretrained weights cháº¥t lÆ°á»£ng cao

**NhÆ°á»£c Ä‘iá»ƒm:**
- âš ï¸ Sá»‘ parameters lá»›n nháº¥t (143.7M)
- âš ï¸ Tá»‘n nhiá»u bá»™ nhá»› vÃ  thá»i gian tÃ­nh toÃ¡n
- âš ï¸ CÃ³ thá»ƒ overfitting vá»›i dá»¯ liá»‡u nhá»

### 4.4. Nháº­n xÃ©t chung

1. **Vá» dá»¯ liá»‡u:**
   - Dataset cÃ³ cháº¥t lÆ°á»£ng tá»‘t, phÃ¢n bá»‘ cÃ¢n báº±ng
   - Sá»‘ lÆ°á»£ng áº£nh vá»«a Ä‘á»§ cho Transfer Learning
   - Data Augmentation hiá»‡u quáº£ trong viá»‡c tÄƒng cÆ°á»ng dá»¯ liá»‡u

2. **Vá» mÃ´ hÃ¬nh:**
   - Táº¥t cáº£ 3 mÃ´ hÃ¬nh Ä‘á»u Ä‘áº¡t accuracy > 80%
   - VGG19 cÃ³ xu hÆ°á»›ng Ä‘áº¡t accuracy cao nháº¥t
   - MobileNetV2 phÃ¹ há»£p nháº¥t cho á»©ng dá»¥ng mobile

3. **Vá» phÆ°Æ¡ng phÃ¡p:**
   - Transfer Learning hiá»‡u quáº£ cho bÃ i toÃ¡n nÃ y
   - Early Stopping giÃºp trÃ¡nh overfitting
   - Data Augmentation cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ hiá»‡u suáº¥t

---

## 5. Äá»ŠNH HÆ¯á»šNG PHÃT TRIá»‚N CHO Láº¦N BÃO CÃO CUá»I CÃ™NG

### 5.1. Cáº£i thiá»‡n mÃ´ hÃ¬nh

#### 5.1.1. Thá»­ nghiá»‡m cÃ¡c mÃ´ hÃ¬nh tiÃªn tiáº¿n hÆ¡n

| MÃ´ hÃ¬nh | MÃ´ táº£ | Ká»³ vá»ng |
|---------|-------|---------|
| EfficientNet-B4/B5 | MÃ´ hÃ¬nh SOTA vá»›i compound scaling | Accuracy > 95% |
| Vision Transformer (ViT) | Ãp dá»¥ng Transformer cho CV | Hiá»‡u quáº£ vá»›i dá»¯ liá»‡u lá»›n |
| DenseNet | Dense connections | Táº­n dá»¥ng tá»‘t features |

#### 5.1.2. Fine-tuning nÃ¢ng cao

- **Unfreeze má»™t sá»‘ lá»›p cuá»‘i** cá»§a base model Ä‘á»ƒ tinh chá»‰nh thÃªm
- **Discriminative Learning Rates:** Sá»­ dá»¥ng learning rate khÃ¡c nhau cho cÃ¡c lá»›p
- **Progressive Resizing:** Huáº¥n luyá»‡n vá»›i áº£nh nhá» trÆ°á»›c, sau Ä‘Ã³ tÄƒng kÃ­ch thÆ°á»›c

#### 5.1.3. Data Augmentation nÃ¢ng cao

- **MixUp:** Trá»™n hai áº£nh vá»›i tá»‰ lá»‡ ngáº«u nhiÃªn
- **CutMix:** Cáº¯t vÃ  dÃ¡n má»™t pháº§n cá»§a áº£nh nÃ y vÃ o áº£nh khÃ¡c
- **AutoAugment:** Tá»± Ä‘á»™ng tÃ¬m chiáº¿n lÆ°á»£c augmentation tá»‘i Æ°u

### 5.2. TÄƒng cÆ°á»ng dá»¯ liá»‡u

1. **Thu tháº­p thÃªm dá»¯ liá»‡u:**
   - TÃ¬m kiáº¿m dataset bá»• sung (PlantVillage, iBean, v.v.)
   - Thu tháº­p áº£nh thá»±c táº¿ tá»« nÃ´ng tráº¡i

2. **Synthetic Data:**
   - Sá»­ dá»¥ng GAN Ä‘á»ƒ táº¡o áº£nh tá»•ng há»£p
   - Augmentation vá»›i cÃ¡c biáº¿n Ä‘á»•i phá»©c táº¡p hÆ¡n

### 5.3. ÄÃ¡nh giÃ¡ vÃ  phÃ¢n tÃ­ch

1. **Cross-Validation:**
   - K-Fold Cross-Validation (K=5 hoáº·c 10)
   - ÄÃ¡nh giÃ¡ á»•n Ä‘á»‹nh vÃ  Ä‘Ã¡ng tin cáº­y hÆ¡n

2. **Giáº£i thÃ­ch mÃ´ hÃ¬nh (Explainability):**
   - **Grad-CAM:** Trá»±c quan hÃ³a vÃ¹ng áº£nh mÃ  mÃ´ hÃ¬nh táº­p trung
   - **SHAP values:** Giáº£i thÃ­ch táº§m quan trá»ng cá»§a features

3. **PhÃ¢n tÃ­ch lá»—i:**
   - NghiÃªn cá»©u cÃ¡c trÆ°á»ng há»£p dá»± Ä‘oÃ¡n sai
   - TÃ¬m hiá»ƒu nguyÃªn nhÃ¢n vÃ  Ä‘á» xuáº¥t giáº£i phÃ¡p

### 5.4. Triá»ƒn khai á»©ng dá»¥ng

#### 5.4.1. API Backend

```python
# Sá»­ dá»¥ng FastAPI hoáº·c Flask
from fastapi import FastAPI, UploadFile
import tensorflow as tf

app = FastAPI()
model = tf.keras.models.load_model('best_model.keras')

@app.post("/predict")
async def predict(file: UploadFile):
    # Xá»­ lÃ½ áº£nh vÃ  dá»± Ä‘oÃ¡n
    result = model.predict(processed_image)
    return {"prediction": class_names[result.argmax()]}
```

#### 5.4.2. Mobile Application

- Chuyá»ƒn Ä‘á»•i mÃ´ hÃ¬nh sang TensorFlow Lite
- TÃ­ch há»£p vÃ o á»©ng dá»¥ng Android/iOS
- Cho phÃ©p chá»¥p áº£nh vÃ  nháº­n káº¿t quáº£ ngay láº­p tá»©c

#### 5.4.3. Web Application

- XÃ¢y dá»±ng giao diá»‡n web vá»›i React/Vue.js
- Upload áº£nh vÃ  hiá»ƒn thá»‹ káº¿t quáº£ trá»±c quan
- Dashboard theo dÃµi lá»‹ch sá»­ dá»± Ä‘oÃ¡n

### 5.5. Ensemble Learning

Káº¿t há»£p nhiá»u mÃ´ hÃ¬nh Ä‘á»ƒ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c:

```python
# Voting Ensemble
final_pred = (pred_resnet + pred_mobilenet + pred_vgg) / 3
# Hoáº·c Weighted Voting
final_pred = 0.4*pred_vgg + 0.35*pred_resnet + 0.25*pred_mobilenet
```

---

## 6. Má»¨C Äá»˜ THAM GIA VÃ€ TIáº¾N Äá»˜ THá»°C HIá»†N

### 6.1. PhÃ¢n cÃ´ng nhiá»‡m vá»¥ chi tiáº¿t

| ThÃ nh viÃªn | Nhiá»‡m vá»¥ | MÃ´ hÃ¬nh phá»¥ trÃ¡ch | Tiáº¿n Ä‘á»™ |
|------------|----------|:-----------------:|:-------:|
| **TRáº¦N MINH HIáº¾U** | - Thu tháº­p vÃ  tiá»n xá»­ lÃ½ dá»¯ liá»‡u<br>- Thá»±c hiá»‡n EDA<br>- Huáº¥n luyá»‡n mÃ´ hÃ¬nh ResNet50<br>- Viáº¿t bÃ¡o cÃ¡o tá»•ng há»£p | ResNet50 | âœ… 100% |
| **TRáº¦N MINH HIáº¾U** | - Data Augmentation<br>- Huáº¥n luyá»‡n mÃ´ hÃ¬nh MobileNetV2<br>- ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh káº¿t quáº£<br>- Viáº¿t tÃ i liá»‡u README | MobileNetV2 | âœ… 100% |
| **HIáº¾U, Báº¢O** | - Thiáº¿t káº¿ kiáº¿n trÃºc mÃ´ hÃ¬nh<br>- Huáº¥n luyá»‡n mÃ´ hÃ¬nh VGG19<br>- Tá»‘i Æ°u hyperparameters<br>- Chuáº©n bá»‹ slide thuyáº¿t trÃ¬nh | VGG19 | âœ… 100% |

### 6.2. Má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p

| ThÃ nh viÃªn | Má»©c Ä‘á»™ Ä‘Ã³ng gÃ³p | Chi tiáº¿t |
|------------|:---------------:|----------|
| TRáº¦N MINH HIáº¾U | 33.3% | HoÃ n thÃ nh Ä‘áº§y Ä‘á»§ nhiá»‡m vá»¥ Ä‘Æ°á»£c giao |
| TRáº¦N MINH HIáº¾U | 33.3% | HoÃ n thÃ nh Ä‘áº§y Ä‘á»§ nhiá»‡m vá»¥ Ä‘Æ°á»£c giao |
| Báº¢O | 33.3% | HoÃ n thÃ nh Ä‘áº§y Ä‘á»§ nhiá»‡m vá»¥ Ä‘Æ°á»£c giao |

### 6.3. Timeline thá»±c hiá»‡n

| Tuáº§n | CÃ´ng viá»‡c | Tráº¡ng thÃ¡i |
|:----:|-----------|:----------:|
| 1 | TÃ¬m hiá»ƒu Ä‘á» tÃ i, thu tháº­p dá»¯ liá»‡u | âœ… HoÃ n thÃ nh |
| 2 | EDA, Tiá»n xá»­ lÃ½ dá»¯ liá»‡u | âœ… HoÃ n thÃ nh |
| 3 | XÃ¢y dá»±ng mÃ´ hÃ¬nh ResNet50, MobileNetV2 | âœ… HoÃ n thÃ nh |
| 4 | XÃ¢y dá»±ng mÃ´ hÃ¬nh VGG19, ÄÃ¡nh giÃ¡ | âœ… HoÃ n thÃ nh |
| 5 | So sÃ¡nh, Viáº¿t bÃ¡o cÃ¡o giá»¯a ká»³ | âœ… HoÃ n thÃ nh |
| 6-8 | Cáº£i thiá»‡n mÃ´ hÃ¬nh, Fine-tuning | ğŸ”„ Äang thá»±c hiá»‡n |
| 9-10 | Triá»ƒn khai á»©ng dá»¥ng | ğŸ“… Káº¿ hoáº¡ch |
| 11-12 | HoÃ n thiá»‡n bÃ¡o cÃ¡o cuá»‘i ká»³ | ğŸ“… Káº¿ hoáº¡ch |

### 6.4. CÃ´ng cá»¥ vÃ  tÃ i nguyÃªn sá»­ dá»¥ng

| CÃ´ng cá»¥ | Má»¥c Ä‘Ã­ch |
|---------|----------|
| Python 3.10+ | NgÃ´n ngá»¯ láº­p trÃ¬nh chÃ­nh |
| TensorFlow/Keras 2.15+ | Framework Deep Learning |
| Jupyter Notebook | PhÃ¡t triá»ƒn vÃ  trÃ¬nh bÃ y code |
| Google Colab | GPU miá»…n phÃ­ cho training |
| GitHub | Quáº£n lÃ½ phiÃªn báº£n vÃ  cá»™ng tÃ¡c |
| Kaggle | Nguá»“n dá»¯ liá»‡u |

---

## 7. TÃ€I LIá»†U THAM KHáº¢O

### 7.1. Dataset

1. Bean Leaf Lesions Classification Dataset. Kaggle. Available at: https://www.kaggle.com/datasets/marquis03/bean-leaf-lesions-classification

### 7.2. MÃ´ hÃ¬nh vÃ  Framework

2. K. He, X. Zhang, S. Ren, and J. Sun, "Deep Residual Learning for Image Recognition," in CVPR, 2016.

3. M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L. Chen, "MobileNetV2: Inverted Residuals and Linear Bottlenecks," in CVPR, 2018.

4. K. Simonyan and A. Zisserman, "Very Deep Convolutional Networks for Large-Scale Image Recognition," in ICLR, 2015.

5. TensorFlow Documentation. Available at: https://www.tensorflow.org/tutorials/images/transfer_learning

### 7.3. Ká»¹ thuáº­t

6. Chollet, F. (2017). Xception: Deep Learning with Depthwise Separable Convolutions. In CVPR.

7. Shorten, C., & Khoshgoftaar, T. M. (2019). A survey on Image Data Augmentation for Deep Learning. Journal of Big Data.

### 7.4. á»¨ng dá»¥ng trong NÃ´ng nghiá»‡p

8. Mohanty, S. P., Hughes, D. P., & SalathÃ©, M. (2016). Using deep learning for image-based plant disease detection. Frontiers in plant science.

9. PlantVillage Dataset. Available at: https://plantvillage.psu.edu/

---

## PHá»¤ Lá»¤C

### A. HÆ°á»›ng dáº«n cháº¡y code

1. **CÃ i Ä‘áº·t thÆ° viá»‡n:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Cáº¥u hÃ¬nh Kaggle API:**
   - Táº£i kaggle.json tá»« Kaggle Account Settings
   - Äáº·t vÃ o ~/.kaggle/kaggle.json
   - `chmod 600 ~/.kaggle/kaggle.json`

3. **Táº£i dataset:**
   ```bash
   python download_dataset.py
   ```

4. **Cháº¡y notebook:**
   ```bash
   jupyter notebook bean_leaf_classification.ipynb
   ```

### B. Cáº¥u trÃºc repository

```
KPDL/
â”œâ”€â”€ data/                           # Dataset (gitignored)
â”œâ”€â”€ bean_leaf_classification.ipynb  # Notebook chÃ­nh
â”œâ”€â”€ download_dataset.py             # Script táº£i dataset
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ BÃO_CÃO.md                      # File bÃ¡o cÃ¡o nÃ y
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### C. Káº¿t quáº£ máº«u

*[CÃ¡c hÃ¬nh áº£nh káº¿t quáº£ sáº½ Ä‘Æ°á»£c táº¡o khi cháº¡y notebook]*

---

**Â© 2024 - NhÃ³m Khai PhÃ¡ Dá»¯ Liá»‡u**

**Äá» tÃ i: PhÃ¢n Loáº¡i Váº¿t Bá»‡nh TrÃªn LÃ¡ Äáº­u**
